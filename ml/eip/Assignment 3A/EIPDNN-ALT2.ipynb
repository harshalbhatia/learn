{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efc71a8f4815c3b013307882a0eacd327ff500cd"
      },
      "cell_type": "code",
      "source": "!pip install -q git+https://www.github.com/keras-team/keras-contrib.git",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[31mmxnet 1.3.0.post0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.15.2 which is incompatible.\u001b[0m\n\u001b[31mkmeans-smote 0.1.0 has requirement imbalanced-learn<0.4,>=0.3.1, but you'll have imbalanced-learn 0.5.0.dev0 which is incompatible.\u001b[0m\n\u001b[31mkmeans-smote 0.1.0 has requirement numpy<1.15,>=1.13, but you'll have numpy 1.15.2 which is incompatible.\u001b[0m\n\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 0.4.1.post2 which is incompatible.\u001b[0m\n\u001b[31manaconda-client 1.7.2 has requirement python-dateutil>=2.6.1, but you'll have python-dateutil 2.6.0 which is incompatible.\u001b[0m\n\u001b[31mimbalanced-learn 0.5.0.dev0 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "25864e1812a7d6a7aa2563fdc4d740e0a036fcd3"
      },
      "cell_type": "code",
      "source": "from keras_contrib.callbacks.cyclical_learning_rate import CyclicLR",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import keras\nimport numpy as np\nfrom functools import reduce\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Add\nfrom keras.layers import Convolution2D, MaxPooling2D,SeparableConvolution2D\nfrom keras.utils import np_utils\nfrom keras import backend\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.datasets import mnist\n",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e04949f7fe25a18771d4c423bc21a1c1c6d3348a"
      },
      "cell_type": "code",
      "source": "def plot_hist(history):\n    line1,=plt.plot(history.history['val_acc'],label='val_acc')\n    line2,=plt.plot(history.history['acc'],label='train_acc')\n    plt.legend(handles=[line1, line2])\ndef plot_history(history):\n    nhist={}\n    for k,v in history.items():\n        nhist[k]=merge_nl(history[k])\n    history=nhist\n    line1,=plt.plot(history['train'],label='train_acc')\n    line2,=plt.plot(history['val'],label='val_acc')    \n    plt.legend(handles=[line1, line2])\ndef mf(o,s):\n    if o is None:\n        o=[]\n    o+=s\n    return o\ndef merge_nl(l):\n    return reduce(mf,l,[])\n\ndef model_train():\n    global hist,epochs,batch_size,X_train,Y_train,X_test,Y_test,augment\n    clr= clr = CyclicLR(base_lr=0.001, max_lr=0.006,step_size=2000)\n    if augment:\n        h=model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),steps_per_epoch=len(x_train) / 32,verbose=1, epochs=epochs,validation_data=(X_test,Y_test))\n    else:\n        h=model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1,validation_data=(X_test,Y_test))\n    \n    hist['train'].append(h.history['acc'])\n    hist['val'].append(h.history['val_acc'])",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40351555aee512a82504e420c3c11fbc037e089b"
      },
      "cell_type": "code",
      "source": "(X_train, y_train), (X_test, y_test) = mnist.load_data()",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# print (X_train.shape)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n# plt.imshow(X_train[0])\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nx_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n\ndivider=255\nX_train=X_train/divider\nX_test=X_test/divider\ny_train[:10]\n# Convert 1-dimensional class arrays to 10-dimensional class matrices\nY_train = np_utils.to_categorical(y_train, 10)\nY_test = np_utils.to_categorical(y_test, 10)\n\n# datagen = ImageDataGenerator(\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     horizontal_flip=True)\n\n# datagen.fit(X_train)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8beb2353881c94319a8809ba2cc2e1707777b5b1"
      },
      "cell_type": "code",
      "source": "print(\"==============================HYPER PARAMETERS BEGIN===================================\")",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "==============================HYPER PARAMETERS BEGIN===================================\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b648e60adb383394523ee628d29c66bbd2690720"
      },
      "cell_type": "code",
      "source": "dropout=0.1\naugment=False\n\nhist={'train':[],'val':[]} #store history\n\nmaxpool=False\nmaxpools=2\n\nsep_conv=True\nsep_conv_last=True\n\nkernels=[]\nconvolutions=[]\nmodel_num=1\n\nmodel_dict={\n    0:{'kernels':[5,10,20,30,40,25,25,20,20],               'convolutions':[3,3,3,3,3,1,3,1,3],'last_conv_size':14},\n    1:{'kernels':[5,10,20,30,40,33,33,25,25,20,20],         'convolutions':[3,3,3,3,3,1,3,1,3,1,3],'last_conv_size':12},\n    2:{'kernels':[5, 5,10,10,20,20,30,30,40,40,25,25,20,20],'convolutions':[1,3,1,3,1,3,1,3,1,3,1,3,1,3],'last_conv_size':14},\n    \n    \n}\n# kernels=[5,5,10,10,20,20,30,30, 40, 40,25,25,20,20]\n# convolutions=[1,3,1,3,1,3,1,3, 1,3, 1, 3, 1, 3]\n# kernels=[5,10,20,30,40,33,33,25,25,20,20]\n# convolutions=[3,3,3,3, 1,3, 1, 3, 1, 3]\n# kernels=[5,10,20,30,  40,25,25,20,20]\n# convolutions=[3,3,3,3, 3, 1, 3, 1, 3]\n\nmaxpool_indices={}\n# last_conv_size=14\nlast_conv_kernels=10",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d522efb0828bb0f5cbcf9de430d43ac4c17307b"
      },
      "cell_type": "code",
      "source": "print(\"==============================HYPER PARAMETERS END===================================\")",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "==============================HYPER PARAMETERS END===================================\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc8b2291fbc48468193ab787261b499a57079cc2"
      },
      "cell_type": "code",
      "source": "from keras.layers import Activation\n\nkernels,convolutions,last_conv_size=model_dict[model_num].values()\nif maxpool:\n    maxpool_indices={4:True,6:True}\n    last_conv_size=int(last_conv_size/(2**maxpools))\n#len(kernels)%(maxpools+1)==0\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(28,28,1)))\nfor i in range(len(kernels)):\n    model.add(BatchNormalization())\n    if sep_conv:\n        model.add(SeparableConvolution2D(kernels[i],(convolutions[i],1)))\n        model.add(SeparableConvolution2D(kernels[i],(1,convolutions[i])))\n        model.add(Activation('relu'))\n    else:\n        model.add(Convolution2D(kernels[i], convolutions[i],activation='relu'))\n        \n    if maxpool and maxpool_indices.get(i):\n        model.add(MaxPooling2D(pool_size=(2,2)))\n    if dropout>0:\n        model.add(Dropout(dropout))\n    \n        \nmodel.add(BatchNormalization())\nif sep_conv_last:\n    model.add(SeparableConvolution2D(last_conv_kernels,(last_conv_size,1)))\n    model.add(SeparableConvolution2D(last_conv_kernels,(1,last_conv_size)))\n    model.add(Activation('relu'))\nelse:\n    model.add(Convolution2D(last_conv_kernels, last_conv_size,activation='relu'))\n    \nmodel.add(Flatten())\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\nmodel.summary()",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization_14 (Batc (None, 28, 28, 1)         4         \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 28, 28, 1)         4         \n_________________________________________________________________\nseparable_conv2d_25 (Separab (None, 26, 28, 5)         13        \n_________________________________________________________________\nseparable_conv2d_26 (Separab (None, 26, 26, 5)         45        \n_________________________________________________________________\nactivation_14 (Activation)   (None, 26, 26, 5)         0         \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 26, 26, 5)         0         \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 26, 26, 5)         20        \n_________________________________________________________________\nseparable_conv2d_27 (Separab (None, 24, 26, 10)        75        \n_________________________________________________________________\nseparable_conv2d_28 (Separab (None, 24, 24, 10)        140       \n_________________________________________________________________\nactivation_15 (Activation)   (None, 24, 24, 10)        0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 24, 24, 10)        0         \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 24, 24, 10)        40        \n_________________________________________________________________\nseparable_conv2d_29 (Separab (None, 22, 24, 20)        250       \n_________________________________________________________________\nseparable_conv2d_30 (Separab (None, 22, 22, 20)        480       \n_________________________________________________________________\nactivation_16 (Activation)   (None, 22, 22, 20)        0         \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 22, 22, 20)        0         \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 22, 22, 20)        80        \n_________________________________________________________________\nseparable_conv2d_31 (Separab (None, 20, 22, 30)        690       \n_________________________________________________________________\nseparable_conv2d_32 (Separab (None, 20, 20, 30)        1020      \n_________________________________________________________________\nactivation_17 (Activation)   (None, 20, 20, 30)        0         \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 20, 20, 30)        0         \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 20, 20, 30)        120       \n_________________________________________________________________\nseparable_conv2d_33 (Separab (None, 18, 20, 40)        1330      \n_________________________________________________________________\nseparable_conv2d_34 (Separab (None, 18, 18, 40)        1760      \n_________________________________________________________________\nactivation_18 (Activation)   (None, 18, 18, 40)        0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 18, 18, 40)        0         \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 18, 18, 40)        160       \n_________________________________________________________________\nseparable_conv2d_35 (Separab (None, 18, 18, 33)        1393      \n_________________________________________________________________\nseparable_conv2d_36 (Separab (None, 18, 18, 33)        1155      \n_________________________________________________________________\nactivation_19 (Activation)   (None, 18, 18, 33)        0         \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 18, 18, 33)        0         \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 18, 18, 33)        132       \n_________________________________________________________________\nseparable_conv2d_37 (Separab (None, 16, 18, 33)        1221      \n_________________________________________________________________\nseparable_conv2d_38 (Separab (None, 16, 16, 33)        1221      \n_________________________________________________________________\nactivation_20 (Activation)   (None, 16, 16, 33)        0         \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 16, 16, 33)        0         \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 16, 16, 33)        132       \n_________________________________________________________________\nseparable_conv2d_39 (Separab (None, 16, 16, 25)        883       \n_________________________________________________________________\nseparable_conv2d_40 (Separab (None, 16, 16, 25)        675       \n_________________________________________________________________\nactivation_21 (Activation)   (None, 16, 16, 25)        0         \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 16, 16, 25)        0         \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 16, 16, 25)        100       \n_________________________________________________________________\nseparable_conv2d_41 (Separab (None, 14, 16, 25)        725       \n_________________________________________________________________\nseparable_conv2d_42 (Separab (None, 14, 14, 25)        725       \n_________________________________________________________________\nactivation_22 (Activation)   (None, 14, 14, 25)        0         \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 14, 14, 25)        0         \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 14, 14, 25)        100       \n_________________________________________________________________\nseparable_conv2d_43 (Separab (None, 14, 14, 20)        545       \n_________________________________________________________________\nseparable_conv2d_44 (Separab (None, 14, 14, 20)        440       \n_________________________________________________________________\nactivation_23 (Activation)   (None, 14, 14, 20)        0         \n_________________________________________________________________\ndropout_21 (Dropout)         (None, 14, 14, 20)        0         \n_________________________________________________________________\nbatch_normalization_25 (Batc (None, 14, 14, 20)        80        \n_________________________________________________________________\nseparable_conv2d_45 (Separab (None, 12, 14, 20)        480       \n_________________________________________________________________\nseparable_conv2d_46 (Separab (None, 12, 12, 20)        480       \n_________________________________________________________________\nactivation_24 (Activation)   (None, 12, 12, 20)        0         \n_________________________________________________________________\ndropout_22 (Dropout)         (None, 12, 12, 20)        0         \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 12, 12, 20)        80        \n_________________________________________________________________\nseparable_conv2d_47 (Separab (None, 1, 12, 10)         450       \n_________________________________________________________________\nseparable_conv2d_48 (Separab (None, 1, 1, 10)          230       \n_________________________________________________________________\nactivation_25 (Activation)   (None, 1, 1, 10)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 10)                0         \n_________________________________________________________________\nactivation_26 (Activation)   (None, 10)                0         \n=================================================================\nTotal params: 17,478\nTrainable params: 16,952\nNon-trainable params: 526\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4cb2698f9c3d9a44f84d33d1dbba44e803da279",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "augment=False\nbatch_size,epochs=(32,5) #10 epochs\nmodel_train()",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 115s 2ms/step - loss: 0.3925 - acc: 0.8715 - val_loss: 0.0864 - val_acc: 0.9747\nEpoch 2/5\n60000/60000 [==============================] - 110s 2ms/step - loss: 0.1156 - acc: 0.9634 - val_loss: 0.0670 - val_acc: 0.9792\nEpoch 3/5\n60000/60000 [==============================] - 110s 2ms/step - loss: 0.0905 - acc: 0.9715 - val_loss: 0.0702 - val_acc: 0.9773\nEpoch 4/5\n60000/60000 [==============================] - 110s 2ms/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0560 - val_acc: 0.9818\nEpoch 5/5\n60000/60000 [==============================] - 110s 2ms/step - loss: 0.0719 - acc: 0.9780 - val_loss: 0.0432 - val_acc: 0.9858\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "d94a1e1e646c9899b2f3b9b351d94a5a5d741e18"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(64,5) #10 epochs\nmodel_train()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 77s 1ms/step - loss: 0.0546 - acc: 0.9833 - val_loss: 0.0503 - val_acc: 0.9837\nEpoch 2/5\n60000/60000 [==============================] - 77s 1ms/step - loss: 0.0558 - acc: 0.9825 - val_loss: 0.0406 - val_acc: 0.9869\nEpoch 3/5\n60000/60000 [==============================] - 77s 1ms/step - loss: 0.0552 - acc: 0.9830 - val_loss: 0.0388 - val_acc: 0.9875\nEpoch 4/5\n60000/60000 [==============================] - 77s 1ms/step - loss: 0.0524 - acc: 0.9841 - val_loss: 0.0385 - val_acc: 0.9871\nEpoch 5/5\n60000/60000 [==============================] - 77s 1ms/step - loss: 0.0514 - acc: 0.9841 - val_loss: 0.0440 - val_acc: 0.9852\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "784234529b04befda35811bde095ae223b687821"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(128,5) #10 epochs\nmodel_train()",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 61s 1ms/step - loss: 0.0422 - acc: 0.9866 - val_loss: 0.0318 - val_acc: 0.9885\nEpoch 2/5\n60000/60000 [==============================] - 62s 1ms/step - loss: 0.0402 - acc: 0.9879 - val_loss: 0.0335 - val_acc: 0.9883\nEpoch 3/5\n60000/60000 [==============================] - 61s 1ms/step - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0315 - val_acc: 0.9898\nEpoch 4/5\n60000/60000 [==============================] - 61s 1ms/step - loss: 0.0404 - acc: 0.9871 - val_loss: 0.0363 - val_acc: 0.9891\nEpoch 5/5\n60000/60000 [==============================] - 62s 1ms/step - loss: 0.0389 - acc: 0.9881 - val_loss: 0.0308 - val_acc: 0.9898\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26d023d02dbbe9da72fb0c5069aa4fbbc6cee3d5"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(256,5) #10 epochs\nmodel_train()",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 54s 894us/step - loss: 0.0342 - acc: 0.9895 - val_loss: 0.0248 - val_acc: 0.9916\nEpoch 2/5\n60000/60000 [==============================] - 54s 894us/step - loss: 0.0344 - acc: 0.9890 - val_loss: 0.0333 - val_acc: 0.9891\nEpoch 3/5\n60000/60000 [==============================] - 54s 894us/step - loss: 0.0342 - acc: 0.9893 - val_loss: 0.0305 - val_acc: 0.9896\nEpoch 4/5\n60000/60000 [==============================] - 54s 894us/step - loss: 0.0321 - acc: 0.9898 - val_loss: 0.0301 - val_acc: 0.9899\nEpoch 5/5\n60000/60000 [==============================] - 54s 894us/step - loss: 0.0327 - acc: 0.9894 - val_loss: 0.0270 - val_acc: 0.9907\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a0dd9ce9cfce2d071e60e99efa71dbc411123e9"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(512,5) #10 epochs\nmodel_train()",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 50s 828us/step - loss: 0.0291 - acc: 0.9907 - val_loss: 0.0280 - val_acc: 0.9907\nEpoch 2/5\n60000/60000 [==============================] - 50s 828us/step - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0265 - val_acc: 0.9910\nEpoch 3/5\n60000/60000 [==============================] - 50s 828us/step - loss: 0.0286 - acc: 0.9906 - val_loss: 0.0260 - val_acc: 0.9918\nEpoch 4/5\n60000/60000 [==============================] - 50s 828us/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0266 - val_acc: 0.9910\nEpoch 5/5\n60000/60000 [==============================] - 50s 828us/step - loss: 0.0286 - acc: 0.9911 - val_loss: 0.0261 - val_acc: 0.9920\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57e574d3e7c85417d0694296c2412cd01b57f978"
      },
      "cell_type": "code",
      "source": "plot_history(hist)\nscore = model.evaluate(X_test, Y_test, verbose=0)\nprint(score) # 9887, 9861, 9791",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[0.02609374901270203, 0.992]\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ba7c8103e26ab9a5e44db977f6e40cc0e53b1b2"
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom matplotlib import pyplot as plt\nfrom keras import backend as K\n%matplotlib inline\n# util function to convert a tensor into a valid image\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x /= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    #x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\ndef vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n                      layer_name = 'conv2d_14'):\n    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n    layer_output = layer_dict[layer_name].output\n    img_ascs = list()\n    for filter_index in range(layer_output.shape[3]):\n        # build a loss function that maximizes the activation\n        # of the nth filter of the layer considered\n        loss = K.mean(layer_output[:, :, :, filter_index])\n\n        # compute the gradient of the input picture wrt this loss\n        grads = K.gradients(loss, model.input)[0]\n\n        # normalization trick: we normalize the gradient\n        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n        # this function returns the loss and grads given the input picture\n        iterate = K.function([model.input], [loss, grads])\n\n        # step size for gradient ascent\n        step = 5.\n\n        img_asc = np.array(img)\n        # run gradient ascent for 20 steps\n        for i in range(20):\n            loss_value, grads_value = iterate([img_asc])\n            img_asc += grads_value * step\n\n        img_asc = img_asc[0]\n        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n        \n    if layer_output.shape[3] >= 35:\n        plot_x, plot_y = 6, 6\n    elif layer_output.shape[3] >= 23:\n        plot_x, plot_y = 4, 6\n    elif layer_output.shape[3] >= 11:\n        plot_x, plot_y = 2, 6\n    else:\n        plot_x, plot_y = 1, 2\n    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n    ax[0, 0].set_title('Input image')\n    fig.suptitle('Input image and %s filters' % (layer_name,))\n    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n        if x == 0 and y == 0:\n            continue\n        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "578a615cc0b298afd83d79c86d6c1f7aeffabc93"
      },
      "cell_type": "code",
      "source": "# layers = [layer.name for layer in model.layers]\n# print(layers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b439892287722e554756db35899ec144b1b7f97c"
      },
      "cell_type": "code",
      "source": "# vis_img_in_filter(layer_name='conv2d_11')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f2aa7be296b57f5048208d11e38e9d414a101e6"
      },
      "cell_type": "code",
      "source": "# vis_img_in_filter(layer_name='conv2d_15')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "550ae2afa0d13f9a5a55d6277ff6233f28e5b8d1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}