{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efc71a8f4815c3b013307882a0eacd327ff500cd"
      },
      "cell_type": "code",
      "source": "!pip install -q git+https://www.github.com/keras-team/keras-contrib.git",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[31mmxnet 1.3.0.post0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.15.2 which is incompatible.\u001b[0m\n\u001b[31mkmeans-smote 0.1.0 has requirement imbalanced-learn<0.4,>=0.3.1, but you'll have imbalanced-learn 0.5.0.dev0 which is incompatible.\u001b[0m\n\u001b[31mkmeans-smote 0.1.0 has requirement numpy<1.15,>=1.13, but you'll have numpy 1.15.2 which is incompatible.\u001b[0m\n\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 0.4.1.post2 which is incompatible.\u001b[0m\n\u001b[31manaconda-client 1.7.2 has requirement python-dateutil>=2.6.1, but you'll have python-dateutil 2.6.0 which is incompatible.\u001b[0m\n\u001b[31mimbalanced-learn 0.5.0.dev0 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "25864e1812a7d6a7aa2563fdc4d740e0a036fcd3"
      },
      "cell_type": "code",
      "source": "from keras_contrib.callbacks.cyclical_learning_rate import CyclicLR",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import keras\nimport numpy as np\nfrom functools import reduce\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Add\nfrom keras.layers import Convolution2D, MaxPooling2D,SeparableConvolution2D\nfrom keras.utils import np_utils\nfrom keras import backend\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.datasets import mnist\n",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e04949f7fe25a18771d4c423bc21a1c1c6d3348a"
      },
      "cell_type": "code",
      "source": "def plot_hist(history):\n    line1,=plt.plot(history.history['val_acc'],label='val_acc')\n    line2,=plt.plot(history.history['acc'],label='train_acc')\n    plt.legend(handles=[line1, line2])\ndef plot_history(history):\n    nhist={}\n    for k,v in history.items():\n        nhist[k]=merge_nl(history[k])\n    history=nhist\n    line1,=plt.plot(history['train'],label='train_acc')\n    line2,=plt.plot(history['val'],label='val_acc')    \n    plt.legend(handles=[line1, line2])\ndef mf(o,s):\n    if o is None:\n        o=[]\n    o+=s\n    return o\ndef merge_nl(l):\n    return reduce(mf,l,[])\n\ndef model_train():\n    global hist,epochs,batch_size,X_train,Y_train,X_test,Y_test,augment\n    clr= clr = CyclicLR(base_lr=0.001, max_lr=0.006,step_size=2000)\n    if augment:\n        h=model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),steps_per_epoch=len(x_train) / 32,verbose=1, epochs=epochs,validation_data=(X_test,Y_test))\n    else:\n        h=model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1,validation_data=(X_test,Y_test))\n    \n    hist['train'].append(h.history['acc'])\n    hist['val'].append(h.history['val_acc'])",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40351555aee512a82504e420c3c11fbc037e089b"
      },
      "cell_type": "code",
      "source": "(X_train, y_train), (X_test, y_test) = mnist.load_data()",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# print (X_train.shape)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n# plt.imshow(X_train[0])\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nx_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n\ndivider=255\nX_train=X_train/divider\nX_test=X_test/divider\ny_train[:10]\n# Convert 1-dimensional class arrays to 10-dimensional class matrices\nY_train = np_utils.to_categorical(y_train, 10)\nY_test = np_utils.to_categorical(y_test, 10)\n\n# datagen = ImageDataGenerator(\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     horizontal_flip=True)\n\n# datagen.fit(X_train)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8beb2353881c94319a8809ba2cc2e1707777b5b1"
      },
      "cell_type": "code",
      "source": "print(\"==============================HYPER PARAMETERS BEGIN===================================\")",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "==============================HYPER PARAMETERS BEGIN===================================\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b648e60adb383394523ee628d29c66bbd2690720"
      },
      "cell_type": "code",
      "source": "dropout=0.1\naugment=False\n\nhist={'train':[],'val':[]} #store history\n\nmaxpool=False\nmaxpools=2\n\nsep_conv=True\nsep_conv_last=True\n\nkernels=[]\nconvolutions=[]\nmodel_num=0\n\nmodel_dict={\n    0:{'kernels':[5,10,20,30,40,25,25,20,20],               'convolutions':[3,3,3,3,3,1,3,1,3],'last_conv_size':14},\n    1:{'kernels':[5,10,20,30,40,33,33,25,25,20,20],         'convolutions':[3,3,3,3,3,1,3,1,3,1,3],'last_conv_size':12},\n    2:{'kernels':[5, 5,10,10,20,20,30,30,40,40,25,25,20,20],'convolutions':[1,3,1,3,1,3,1,3,1,3,1,3,1,3],'last_conv_size':14},\n}\n# kernels=[5,5,10,10,20,20,30,30, 40, 40,25,25,20,20]\n# convolutions=[1,3,1,3,1,3,1,3, 1,3, 1, 3, 1, 3]\n# kernels=[5,10,20,30,40,33,33,25,25,20,20]\n# convolutions=[3,3,3,3, 1,3, 1, 3, 1, 3]\n# kernels=[5,10,20,30,  40,25,25,20,20]\n# convolutions=[3,3,3,3, 3, 1, 3, 1, 3]\n\nmaxpool_indices={}\n# last_conv_size=14\nlast_conv_kernels=10",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d522efb0828bb0f5cbcf9de430d43ac4c17307b"
      },
      "cell_type": "code",
      "source": "print(\"==============================HYPER PARAMETERS END===================================\")",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "==============================HYPER PARAMETERS END===================================\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc8b2291fbc48468193ab787261b499a57079cc2"
      },
      "cell_type": "code",
      "source": "from keras.layers import Activation\n\nkernels,convolutions,last_conv_size=model_dict[model_num].values()\nif maxpool:\n    maxpool_indices={4:True,6:True}\n    last_conv_size=int(last_conv_size/(2**maxpools))\n#len(kernels)%(maxpools+1)==0\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(28,28,1)))\nfor i in range(len(kernels)):\n    model.add(BatchNormalization())\n    if sep_conv:\n        model.add(SeparableConvolution2D(kernels[i],(convolutions[i],1)))\n        model.add(SeparableConvolution2D(kernels[i],(1,convolutions[i])))\n        model.add(Activation('relu'))\n    else:\n        model.add(Convolution2D(kernels[i], convolutions[i],activation='relu'))\n        \n    if maxpool and maxpool_indices.get(i):\n        model.add(MaxPooling2D(pool_size=(2,2)))\n    if dropout>0:\n        model.add(Dropout(dropout))\n    \n        \nmodel.add(BatchNormalization())\nif sep_conv_last:\n    model.add(SeparableConvolution2D(last_conv_kernels,(last_conv_size,1)))\n    model.add(SeparableConvolution2D(last_conv_kernels,(1,last_conv_size)))\n    model.add(Activation('relu'))\nelse:\n    model.add(Convolution2D(last_conv_kernels, last_conv_size,activation='relu'))\n    \nmodel.add(Flatten())\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\nmodel.summary()",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization_12 (Batc (None, 28, 28, 1)         4         \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 28, 28, 1)         4         \n_________________________________________________________________\nseparable_conv2d_21 (Separab (None, 26, 28, 5)         13        \n_________________________________________________________________\nseparable_conv2d_22 (Separab (None, 26, 26, 5)         45        \n_________________________________________________________________\nactivation_12 (Activation)   (None, 26, 26, 5)         0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 26, 26, 5)         0         \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 26, 26, 5)         20        \n_________________________________________________________________\nseparable_conv2d_23 (Separab (None, 24, 26, 10)        75        \n_________________________________________________________________\nseparable_conv2d_24 (Separab (None, 24, 24, 10)        140       \n_________________________________________________________________\nactivation_13 (Activation)   (None, 24, 24, 10)        0         \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 24, 24, 10)        0         \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 24, 24, 10)        40        \n_________________________________________________________________\nseparable_conv2d_25 (Separab (None, 22, 24, 20)        250       \n_________________________________________________________________\nseparable_conv2d_26 (Separab (None, 22, 22, 20)        480       \n_________________________________________________________________\nactivation_14 (Activation)   (None, 22, 22, 20)        0         \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 22, 22, 20)        0         \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 22, 22, 20)        80        \n_________________________________________________________________\nseparable_conv2d_27 (Separab (None, 20, 22, 30)        690       \n_________________________________________________________________\nseparable_conv2d_28 (Separab (None, 20, 20, 30)        1020      \n_________________________________________________________________\nactivation_15 (Activation)   (None, 20, 20, 30)        0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 20, 20, 30)        0         \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 20, 20, 30)        120       \n_________________________________________________________________\nseparable_conv2d_29 (Separab (None, 18, 20, 40)        1330      \n_________________________________________________________________\nseparable_conv2d_30 (Separab (None, 18, 18, 40)        1760      \n_________________________________________________________________\nactivation_16 (Activation)   (None, 18, 18, 40)        0         \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 18, 18, 40)        0         \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 18, 18, 40)        160       \n_________________________________________________________________\nseparable_conv2d_31 (Separab (None, 18, 18, 25)        1065      \n_________________________________________________________________\nseparable_conv2d_32 (Separab (None, 18, 18, 25)        675       \n_________________________________________________________________\nactivation_17 (Activation)   (None, 18, 18, 25)        0         \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 18, 18, 25)        0         \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 18, 18, 25)        100       \n_________________________________________________________________\nseparable_conv2d_33 (Separab (None, 16, 18, 25)        725       \n_________________________________________________________________\nseparable_conv2d_34 (Separab (None, 16, 16, 25)        725       \n_________________________________________________________________\nactivation_18 (Activation)   (None, 16, 16, 25)        0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 16, 16, 25)        0         \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 16, 16, 25)        100       \n_________________________________________________________________\nseparable_conv2d_35 (Separab (None, 16, 16, 20)        545       \n_________________________________________________________________\nseparable_conv2d_36 (Separab (None, 16, 16, 20)        440       \n_________________________________________________________________\nactivation_19 (Activation)   (None, 16, 16, 20)        0         \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 16, 16, 20)        0         \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 16, 16, 20)        80        \n_________________________________________________________________\nseparable_conv2d_37 (Separab (None, 14, 16, 20)        480       \n_________________________________________________________________\nseparable_conv2d_38 (Separab (None, 14, 14, 20)        480       \n_________________________________________________________________\nactivation_20 (Activation)   (None, 14, 14, 20)        0         \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 14, 14, 20)        0         \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 14, 14, 20)        80        \n_________________________________________________________________\nseparable_conv2d_39 (Separab (None, 1, 14, 10)         490       \n_________________________________________________________________\nseparable_conv2d_40 (Separab (None, 1, 1, 10)          250       \n_________________________________________________________________\nactivation_21 (Activation)   (None, 1, 1, 10)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 10)                0         \n_________________________________________________________________\nactivation_22 (Activation)   (None, 10)                0         \n=================================================================\nTotal params: 12,466\nTrainable params: 12,072\nNon-trainable params: 394\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4cb2698f9c3d9a44f84d33d1dbba44e803da279",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "augment=False\nbatch_size,epochs=(32,5) #7 epochs neeede, 1 extra just in case\nmodel_train()",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 104s 2ms/step - loss: 0.3772 - acc: 0.8794 - val_loss: 0.0993 - val_acc: 0.9693\nEpoch 2/5\n60000/60000 [==============================] - 100s 2ms/step - loss: 0.1157 - acc: 0.9643 - val_loss: 0.0805 - val_acc: 0.9742\nEpoch 3/5\n60000/60000 [==============================] - 100s 2ms/step - loss: 0.0921 - acc: 0.9718 - val_loss: 0.0709 - val_acc: 0.9778\nEpoch 4/5\n60000/60000 [==============================] - 100s 2ms/step - loss: 0.0805 - acc: 0.9749 - val_loss: 0.0510 - val_acc: 0.9830\nEpoch 5/5\n60000/60000 [==============================] - 100s 2ms/step - loss: 0.0723 - acc: 0.9773 - val_loss: 0.0891 - val_acc: 0.9725\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "d94a1e1e646c9899b2f3b9b351d94a5a5d741e18"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(64,5)\nmodel_train()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 69s 1ms/step - loss: 0.0571 - acc: 0.9814 - val_loss: 0.0412 - val_acc: 0.9879\nEpoch 2/5\n60000/60000 [==============================] - 69s 1ms/step - loss: 0.0538 - acc: 0.9829 - val_loss: 0.0401 - val_acc: 0.9864\nEpoch 3/5\n60000/60000 [==============================] - 69s 1ms/step - loss: 0.0537 - acc: 0.9832 - val_loss: 0.0338 - val_acc: 0.9892\nEpoch 4/5\n60000/60000 [==============================] - 69s 1ms/step - loss: 0.0523 - acc: 0.9835 - val_loss: 0.0379 - val_acc: 0.9883\nEpoch 5/5\n60000/60000 [==============================] - 69s 1ms/step - loss: 0.0512 - acc: 0.9839 - val_loss: 0.0436 - val_acc: 0.9852\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4efe817c993b122e282a5f3377236838a610dd7c"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(128,5) \nmodel_train()",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 55s 920us/step - loss: 0.0409 - acc: 0.9871 - val_loss: 0.0295 - val_acc: 0.9903\nEpoch 2/5\n60000/60000 [==============================] - 55s 920us/step - loss: 0.0412 - acc: 0.9869 - val_loss: 0.0323 - val_acc: 0.9905\nEpoch 3/5\n60000/60000 [==============================] - 55s 921us/step - loss: 0.0388 - acc: 0.9875 - val_loss: 0.0314 - val_acc: 0.9899\nEpoch 4/5\n60000/60000 [==============================] - 55s 919us/step - loss: 0.0412 - acc: 0.9869 - val_loss: 0.0287 - val_acc: 0.9917\nEpoch 5/5\n60000/60000 [==============================] - 55s 921us/step - loss: 0.0392 - acc: 0.9879 - val_loss: 0.0306 - val_acc: 0.9895\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "784234529b04befda35811bde095ae223b687821"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(256,5)\nmodel_train()",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 48s 805us/step - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0226 - val_acc: 0.9926\nEpoch 2/5\n60000/60000 [==============================] - 48s 805us/step - loss: 0.0338 - acc: 0.9890 - val_loss: 0.0248 - val_acc: 0.9927\nEpoch 3/5\n60000/60000 [==============================] - 48s 805us/step - loss: 0.0326 - acc: 0.9892 - val_loss: 0.0270 - val_acc: 0.9916\nEpoch 4/5\n60000/60000 [==============================] - 48s 805us/step - loss: 0.0318 - acc: 0.9895 - val_loss: 0.0236 - val_acc: 0.9931\nEpoch 5/5\n60000/60000 [==============================] - 48s 804us/step - loss: 0.0325 - acc: 0.9894 - val_loss: 0.0275 - val_acc: 0.9910\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9a30c3a4404f411fe263d4908419d35ce24b301"
      },
      "cell_type": "code",
      "source": "batch_size,epochs=(512,5)\nmodel_train()",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 45s 742us/step - loss: 0.0313 - acc: 0.9901 - val_loss: 0.0223 - val_acc: 0.9934\nEpoch 2/5\n60000/60000 [==============================] - 45s 742us/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.0213 - val_acc: 0.9932\nEpoch 3/5\n60000/60000 [==============================] - 45s 742us/step - loss: 0.0294 - acc: 0.9908 - val_loss: 0.0230 - val_acc: 0.9928\nEpoch 4/5\n60000/60000 [==============================] - 45s 743us/step - loss: 0.0291 - acc: 0.9905 - val_loss: 0.0222 - val_acc: 0.9931\nEpoch 5/5\n60000/60000 [==============================] - 45s 743us/step - loss: 0.0286 - acc: 0.9906 - val_loss: 0.0228 - val_acc: 0.9933\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57e574d3e7c85417d0694296c2412cd01b57f978"
      },
      "cell_type": "code",
      "source": "plot_history(hist)\nscore = model.evaluate(X_test, Y_test, verbose=0)\nprint(score) # 9887, 9861, 9791",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[0.022849948052992113, 0.9933]\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ba7c8103e26ab9a5e44db977f6e40cc0e53b1b2"
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom matplotlib import pyplot as plt\nfrom keras import backend as K\n%matplotlib inline\n# util function to convert a tensor into a valid image\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x /= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    #x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\ndef vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n                      layer_name = 'conv2d_14'):\n    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n    layer_output = layer_dict[layer_name].output\n    img_ascs = list()\n    for filter_index in range(layer_output.shape[3]):\n        # build a loss function that maximizes the activation\n        # of the nth filter of the layer considered\n        loss = K.mean(layer_output[:, :, :, filter_index])\n\n        # compute the gradient of the input picture wrt this loss\n        grads = K.gradients(loss, model.input)[0]\n\n        # normalization trick: we normalize the gradient\n        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n        # this function returns the loss and grads given the input picture\n        iterate = K.function([model.input], [loss, grads])\n\n        # step size for gradient ascent\n        step = 5.\n\n        img_asc = np.array(img)\n        # run gradient ascent for 20 steps\n        for i in range(20):\n            loss_value, grads_value = iterate([img_asc])\n            img_asc += grads_value * step\n\n        img_asc = img_asc[0]\n        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n        \n    if layer_output.shape[3] >= 35:\n        plot_x, plot_y = 6, 6\n    elif layer_output.shape[3] >= 23:\n        plot_x, plot_y = 4, 6\n    elif layer_output.shape[3] >= 11:\n        plot_x, plot_y = 2, 6\n    else:\n        plot_x, plot_y = 1, 2\n    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n    ax[0, 0].set_title('Input image')\n    fig.suptitle('Input image and %s filters' % (layer_name,))\n    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n        if x == 0 and y == 0:\n            continue\n        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "578a615cc0b298afd83d79c86d6c1f7aeffabc93"
      },
      "cell_type": "code",
      "source": "# layers = [layer.name for layer in model.layers]\n# print(layers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b439892287722e554756db35899ec144b1b7f97c"
      },
      "cell_type": "code",
      "source": "# vis_img_in_filter(layer_name='conv2d_11')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f2aa7be296b57f5048208d11e38e9d414a101e6"
      },
      "cell_type": "code",
      "source": "# vis_img_in_filter(layer_name='conv2d_15')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "550ae2afa0d13f9a5a55d6277ff6233f28e5b8d1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}