Session 1
spiking neural nets
bored cat experiment
kernel/feature extractor => feature => channel
same kernel =>similar features => 1 channel
1 kernel => 1 channel
Typora
MathJax


===============================================================================
Session 2
since batch size is less like 32, un common stuff wont be amplified
softmax not used in accuracy critical
three blue and one brown
unsupervised => rewards
supervised => loss/error
net-disect
===============================================================================
Session 3
unet, deconvolution
theano
disadvantage of dept convo
Xception network
label smoothing works very well!


cycling learning rate is awesome
use sgd and adam or reverse for improved accuracy
