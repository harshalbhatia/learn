{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-4-normal-clr.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "f67729355a01c19c62bfa2145d9594b1da821fc6",
        "id": "ekEW8cpCZTfx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q six numpy scipy matplotlib scikit-image opencv-python imageio\n",
        "!pip install -q keras imgaug\n",
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "QnWB8WdJZTf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "363049cf0704e0aebfa7ea4994c6c291fd66cbac",
        "id": "l4HcyUjGZTgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import *\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# from keras.callbacks import LearningRateScheduler,ModelCheckpoint,EarlyStopping,LambdaCallback\n",
        "import os,sys,math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22f446b53ec82f3244c33dd780ab24b896178cf9",
        "id": "udQldM9iZTgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "92df9b3e-8e90-4a5d-ebbd-ecc40252f57f"
      },
      "cell_type": "code",
      "source": [
        "import google\n",
        "colab_dir='./'\n",
        "file_name='EIP_CIFAR_10'\n",
        "if hasattr(google,'colab'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    colab_dir='/content/gdrive/My Drive/Colab Notebooks/'\n",
        "model_file=colab_dir+file_name+'.h5'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "7eckJNC7ZTgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa9bb45cb7f0171c15c4b065ade989e82042b15a",
        "id": "Y9VzAQw_ZTgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Augmentation and resizing\n",
        "#augment and then concat samples with original\n",
        "def augment(dataset,flip=0.5,blur=1.0):\n",
        "    ia.seed(1)\n",
        "#     seq = iaa.Sequential([iaa.Fliplr(flip),iaa.GaussianBlur(sigma=(0, blur)),iaa.Sometimes(iaa.Crop(percent=(0, 0.1))),\n",
        "#                          iaa.Sometimes(iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "#                                              translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "#                                              rotate=(-45, 45),shear=(-16, 16),order=[0, 1],cval=(0, 255),mode=ia.ALL))])\n",
        "    seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Crop(percent=(0, 0.1)),\n",
        "    iaa.Sometimes(0.5,\n",
        "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "    ),\n",
        "    #iaa.ContrastNormalization((0.75, 1.5)),\n",
        "    #iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "    #iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "    #iaa.Affine(\n",
        "    #    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "    #    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "    #    rotate=(-25, 25),\n",
        "    #    shear=(-8, 8))\n",
        "    ], random_order=True)    \n",
        "    return seq.augment_images(dataset)\n",
        "\n",
        "def augmenter(X,y,start=0,end=1):\n",
        "    ln=len(X)\n",
        "    print('Before augmentation:',X.shape,y.shape)\n",
        "    start=int(start*ln)\n",
        "    end=int(end*ln)\n",
        "    new_X=augment(X)[start:end]\n",
        "    new_y=y[start:end]\n",
        "    X=np.concatenate((X,new_X))\n",
        "    y=np.concatenate((y,new_y))\n",
        "    print('After augmentation:',X.shape,y.shape)\n",
        "    return (X,y)\n",
        "\n",
        "#26x26 is almost half of 32x32. 22x22 maybe too small even though its exact half.\n",
        "def resize_imgs(imgs,shape=(26,26)):\n",
        "    seq = iaa.Sequential([iaa.Scale({\"height\": shape[0], \"width\": shape[1]})])\n",
        "    return seq.augment_images(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b55206328faf39cfbc450beddc20dc5a90aa5218",
        "id": "WcHPOUBlZTgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2,num_layers=12):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(num_layers):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*2), (1,1),kernel_initializer='he_normal', use_bias=False ,padding='same')(relu)\n",
        "        BatchNorm = BatchNormalization()(Conv2D_3_3)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter), (3,3),kernel_initializer='he_normal', use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])        \n",
        "        temp = concat        \n",
        "    return temp\n",
        "\n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter), (1,1),kernel_initializer='he_normal', use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "        Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)    \n",
        "    return avg\n",
        "\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)    \n",
        "    return output\n",
        "  \n",
        "def dense_unit(input_layer,num_filter, dropout_rate,num_layers):\n",
        "    dense_block=add_denseblock(input_layer, num_filter, dropout_rate,num_layers)\n",
        "    transition_block=add_transition(dense_block, num_filter, dropout_rate)\n",
        "    return transition_block\n",
        "  \n",
        "def dense_units_chain(n,input_layer,num_filter, dropout_rate,num_layers):\n",
        "    dense_unit_=input_layer\n",
        "    for i in range(n):\n",
        "        dense_unit_=dense_unit(dense_unit_,num_filter, dropout_rate,num_layers)\n",
        "    return dense_unit_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d104b63cd5b877c9d8acd0a7ac991f17befa41ea",
        "id": "Rybsn7hRZTgr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callback classes\n",
        "#try building model with clr, snapshot ensemble\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    \"source: https://github.com/bckenstler/CLR/blob/master/clr_callback.py\"\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "        \n",
        "###################################################################################################\n",
        "###################################################################################################\n",
        "class SnapshotModelCheckpoint(Callback):\n",
        "    \"\"\"source : https://github.com/titu1994/Snapshot-Ensembles/blob/master/snapshot.py\"\"\"\n",
        "    def __init__(self, nb_epochs, nb_snapshots, fn_prefix='Model'):\n",
        "        super(SnapshotModelCheckpoint, self).__init__()\n",
        "\n",
        "        self.check = nb_epochs // nb_snapshots\n",
        "        self.fn_prefix = fn_prefix\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch != 0 and (epoch + 1) % self.check == 0:\n",
        "            filepath = self.fn_prefix + \"-%d.h5\" % ((epoch + 1) // self.check)\n",
        "            self.model.save_weights(filepath, overwrite=True)\n",
        "            #print(\"Saved snapshot at weights/%s_%d.h5\" % (self.fn_prefix, epoch))\n",
        "\n",
        "\n",
        "class SnapshotCallbackBuilder:\n",
        "    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n",
        "        self.T = nb_epochs\n",
        "        self.M = nb_snapshots\n",
        "        self.alpha_zero = init_lr\n",
        "\n",
        "    def get_callbacks(self, model_prefix='Model'):\n",
        "        \"\"\"\n",
        "        Creates a list of callbacks that can be used during training to create a\n",
        "        snapshot ensemble of the model.\n",
        "        Args:\n",
        "            model_prefix: prefix for the filename of the weights.\n",
        "        Returns: list of 3 callbacks [ModelCheckpoint, LearningRateScheduler,\n",
        "                 SnapshotModelCheckpoint] which can be provided to the 'fit' function\n",
        "        \"\"\"\n",
        "        if not os.path.exists('weights/'):\n",
        "            os.makedirs('weights/')\n",
        "\n",
        "        callback_list = [callbacks.ModelCheckpoint(\"weights/%s-Best.h5\" % model_prefix, monitor=\"val_acc\",\n",
        "                                                    save_best_only=True, save_weights_only=True),\n",
        "                         callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule),\n",
        "                         SnapshotModelCheckpoint(self.T, self.M, fn_prefix='weights/%s' % model_prefix)]\n",
        "\n",
        "        return callback_list\n",
        "\n",
        "    def _cosine_anneal_schedule(self, t):\n",
        "        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n",
        "        cos_inner /= self.T // self.M\n",
        "        cos_out = np.cos(cos_inner) + 1\n",
        "        return float(self.alpha_zero / 2 * cos_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85afcd30b9f0ca412bcf7b04938730e52e04bb47",
        "id": "bxSMSYnfZTgy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_prev_model(model_small=None):\n",
        "#     print(os.popen('du -sh '+colab_dir+'*').read())\n",
        "    last_best=os.popen('du -sh '+colab_dir+r'*|sed -r \"s/^[0-9\\.]+[MK]?\\s(.*)$/\\1/g;\"|tail -1').read().strip()\n",
        "    model_prev=None\n",
        "    try:\n",
        "        print('Attempting to load last best model from file - ',end='')\n",
        "        last_best_fn=last_best.split('/')[-1]\n",
        "        last_best_epoch=last_best_fn.split('.')[1].split('-')[0]\n",
        "        model_prev=load_model(last_best)\n",
        "        print('Sucess\\nLoaded '+last_best_fn, 'epoch :', last_best_epoch)\n",
        "    except Exception as e:\n",
        "        print('Failed!\\n',e)\n",
        "        try:\n",
        "            print('Attempting to load last saved model from file - ',end='')\n",
        "            model_prev = load_model(model_file)\n",
        "            print('Sucess\\nLoaded model from file',model_file)\n",
        "        except Exception as e:\n",
        "    #         print(str(e), 'at line ', sys.exc_info()[2].tb_lineno)\n",
        "            print('Failed!\\n',e)\n",
        "            try:\n",
        "                print('Attempting to load in memory, small model - ',end='')\n",
        "                if len(model_small.layers)>1:\n",
        "                    model_prev=model_small\n",
        "                print('Sucess')\n",
        "            except Exception as e:\n",
        "                print('Failed!\\n',e)\n",
        "    return model_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d5f083dfa8904a9bd7433e385ad2a0b8a236b22",
        "id": "ZvXgIPgJZTg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def copy_weights(model_to,model_from):\n",
        "    #model_to.set_weights(model_from.get_weights())\n",
        "    s,err=0,0\n",
        "    print('Trying to copy weights')\n",
        "    try:\n",
        "        if len(model_to.layers) >1 and len(model_from.layers) >1:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        print('Inavlid models',model_to,model_from)\n",
        "        return\n",
        "    for new_layer, layer in zip(model_to.layers[1:], model_from.layers[1:]):\n",
        "        s+=1\n",
        "        try:\n",
        "            new_layer.set_weights(layer.get_weights())\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    print('Done: errors:',err)\n",
        "      \n",
        "#new model with larger i/p layer\n",
        "def larger_model(src_model,shape=(32,32,3)):\n",
        "    new_input=Input(shape)\n",
        "    src_model.layers.pop(0)\n",
        "    new_output=src_model(new_input)\n",
        "    new_model=Model(new_input,new_output)\n",
        "    return new_model\n",
        "\n",
        "# Load CIFAR10 Data\n",
        "def load_data(resize=False,shape=(26,26),test_augment=False):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    \n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    if resize:\n",
        "        x_train=resize_imgs(x_train,shape)\n",
        "        x_test=resize_imgs(x_test,shape)\n",
        "    \n",
        "    (x_train, y_train) = augmenter(x_train, y_train,end=1)\n",
        "    if test_augment:\n",
        "        (x_test, y_test) = augmenter(x_test, y_test,end=1)\n",
        "    return (x_train, y_train,x_test, y_test)\n",
        "#create a dnn model\n",
        "def create_model(input_shape,num_layers,input=None):\n",
        "    print('Creating model with input shape',input_shape)\n",
        "    if input is None:\n",
        "        input = Input(input_shape)\n",
        "    First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "    hidden_dense_blocks = dense_units_chain(n_dense_blocks,First_Conv2D,num_filter,dropout_rate,num_layers)\n",
        "    Last_Block = add_denseblock(hidden_dense_blocks, num_filter, dropout_rate)\n",
        "    output = output_layer(Last_Block)\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "991f8e371577a1f2e8197827dab5aac2406ef1b1",
        "id": "BK6GIDeUZThE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23a23feb-2791-4a84-9998-e6ae90717f80"
      },
      "cell_type": "code",
      "source": [
        "print('====================HYPER PARAMETERS====================')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================HYPER PARAMETERS====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "02c643e295c0bc677da79c821a40e5b15cc3fdaf",
        "id": "4jCzBOwcZThS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "max_epochs = 250\n",
        "model_small_epochs=20\n",
        "model_large_epochs1=100\n",
        "model_large_epochs2=80\n",
        "\n",
        "num_layers = 16\n",
        "# layers_small=12\n",
        "# layers_large=num_layers-layers_small\n",
        "layers_large=layers_small=num_layers\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2\n",
        "n_dense_blocks = 3\n",
        "smaller_input=(26,26,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "275d54ceb5bde42b199b74a7b7fa0b0677874feb",
        "id": "jdGaI9vGZThZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f560e137-3c94-4bf4-e9e6-8c2212dbe099"
      },
      "cell_type": "code",
      "source": [
        "print('====================BEGIN OF SMALLER MODEL====================')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================BEGIN OF SMALLER MODEL====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "4fec52f1aaca7cc57b2152e1b128ed082a482e1b",
        "id": "2P9tqvvaZThj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "838505d8-f31b-4ade-c276-52411dd20403"
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "x_train, y_train, x_test, y_test = load_data(resize=True,shape=smaller_input[:-1])\n",
        "\n",
        "#callbacks\n",
        "model_checkpointer=ModelCheckpoint('small_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',\n",
        "                verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "# early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "clr = CyclicLR(base_lr=0.1, max_lr=0.2,step_size=8*(len(y_train)/batch_size))\n",
        "\n",
        "# callbacks = snapshot.get_callbacks(model_prefix=model_prefix)\n",
        "callbacks = [clr, model_checkpointer]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 17s 0us/step\n",
            "Before augmentation: (50000, 26, 26, 3) (50000, 10)\n",
            "After augmentation: (100000, 26, 26, 3) (100000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a1c8f577fd7d55a94eea1620db6e4a4d0356ec81",
        "id": "ViAneRF1ZThs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20385
        },
        "outputId": "e003adf2-0afd-4229-84a3-c7583584b0fb"
      },
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model_small = create_model((x_train.shape[1:]),num_layers=layers_small)\n",
        "model_small.compile(loss='categorical_crossentropy',metrics=['accuracy'],\n",
        "              optimizer=SGD(lr=0.1, decay=1e-4, momentum=0.9, nesterov=True))\n",
        "model_small.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating model with input shape (26, 26, 3)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 26, 26, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 26, 26, 12)   324         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 26, 26, 12)   48          conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 26, 26, 12)   0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 26, 26, 24)   288         activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 26, 26, 24)   96          conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 26, 26, 24)   0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 26, 26, 12)   2592        activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_190 (Dropout)           (None, 26, 26, 12)   0           conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_181 (Concatenate)   (None, 26, 26, 24)   0           conv2d_373[0][0]                 \n",
            "                                                                 dropout_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 26, 26, 24)   96          concatenate_181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 26, 26, 24)   0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 26, 26, 24)   576         activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 26, 26, 24)   96          conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 26, 26, 24)   0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 26, 26, 12)   2592        activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_191 (Dropout)           (None, 26, 26, 12)   0           conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_182 (Concatenate)   (None, 26, 26, 36)   0           concatenate_181[0][0]            \n",
            "                                                                 dropout_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 26, 26, 36)   144         concatenate_182[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 26, 26, 36)   0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 26, 26, 24)   864         activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 26, 26, 24)   96          conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 26, 26, 24)   0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 26, 26, 12)   2592        activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_192 (Dropout)           (None, 26, 26, 12)   0           conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_183 (Concatenate)   (None, 26, 26, 48)   0           concatenate_182[0][0]            \n",
            "                                                                 dropout_192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 26, 26, 48)   192         concatenate_183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 26, 26, 48)   0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 26, 26, 24)   1152        activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 26, 26, 24)   96          conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 26, 26, 24)   0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 26, 26, 12)   2592        activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_193 (Dropout)           (None, 26, 26, 12)   0           conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_184 (Concatenate)   (None, 26, 26, 60)   0           concatenate_183[0][0]            \n",
            "                                                                 dropout_193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 26, 26, 60)   240         concatenate_184[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 26, 26, 60)   0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 26, 26, 24)   1440        activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 26, 26, 24)   96          conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 26, 26, 24)   0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 26, 26, 12)   2592        activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_194 (Dropout)           (None, 26, 26, 12)   0           conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_185 (Concatenate)   (None, 26, 26, 72)   0           concatenate_184[0][0]            \n",
            "                                                                 dropout_194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 26, 26, 72)   288         concatenate_185[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 26, 26, 72)   0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 26, 26, 24)   1728        activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 26, 26, 24)   96          conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 26, 26, 24)   0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 26, 26, 12)   2592        activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_195 (Dropout)           (None, 26, 26, 12)   0           conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_186 (Concatenate)   (None, 26, 26, 84)   0           concatenate_185[0][0]            \n",
            "                                                                 dropout_195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 26, 26, 84)   336         concatenate_186[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 26, 26, 84)   0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 26, 26, 24)   2016        activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 26, 26, 24)   96          conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 26, 26, 24)   0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 26, 26, 12)   2592        activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_196 (Dropout)           (None, 26, 26, 12)   0           conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_187 (Concatenate)   (None, 26, 26, 96)   0           concatenate_186[0][0]            \n",
            "                                                                 dropout_196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 26, 26, 96)   384         concatenate_187[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 26, 26, 96)   0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 26, 26, 24)   2304        activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 26, 26, 24)   96          conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 26, 26, 24)   0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 26, 26, 12)   2592        activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_197 (Dropout)           (None, 26, 26, 12)   0           conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_188 (Concatenate)   (None, 26, 26, 108)  0           concatenate_187[0][0]            \n",
            "                                                                 dropout_197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 26, 26, 108)  432         concatenate_188[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 26, 26, 108)  0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 26, 26, 24)   2592        activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 26, 26, 24)   96          conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 26, 26, 24)   0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 26, 26, 12)   2592        activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_198 (Dropout)           (None, 26, 26, 12)   0           conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_189 (Concatenate)   (None, 26, 26, 120)  0           concatenate_188[0][0]            \n",
            "                                                                 dropout_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 26, 26, 120)  480         concatenate_189[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 26, 26, 120)  0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 26, 26, 24)   2880        activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 26, 26, 24)   96          conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 26, 26, 24)   0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 26, 26, 12)   2592        activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_199 (Dropout)           (None, 26, 26, 12)   0           conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_190 (Concatenate)   (None, 26, 26, 132)  0           concatenate_189[0][0]            \n",
            "                                                                 dropout_199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 26, 26, 132)  528         concatenate_190[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 26, 26, 132)  0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 26, 26, 24)   3168        activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 26, 26, 24)   96          conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 26, 26, 24)   0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 26, 26, 12)   2592        activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_200 (Dropout)           (None, 26, 26, 12)   0           conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_191 (Concatenate)   (None, 26, 26, 144)  0           concatenate_190[0][0]            \n",
            "                                                                 dropout_200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 26, 26, 144)  576         concatenate_191[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 26, 26, 144)  0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 26, 26, 24)   3456        activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 26, 26, 24)   96          conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 26, 26, 24)   0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 26, 26, 12)   2592        activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_201 (Dropout)           (None, 26, 26, 12)   0           conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_192 (Concatenate)   (None, 26, 26, 156)  0           concatenate_191[0][0]            \n",
            "                                                                 dropout_201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 26, 26, 156)  624         concatenate_192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 26, 26, 156)  0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 26, 26, 24)   3744        activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 26, 26, 24)   96          conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 26, 26, 24)   0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 26, 26, 12)   2592        activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_202 (Dropout)           (None, 26, 26, 12)   0           conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_193 (Concatenate)   (None, 26, 26, 168)  0           concatenate_192[0][0]            \n",
            "                                                                 dropout_202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 26, 26, 168)  672         concatenate_193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 26, 26, 168)  0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 26, 26, 24)   4032        activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 26, 26, 24)   96          conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 26, 26, 24)   0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 26, 26, 12)   2592        activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 26, 26, 12)   0           conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_194 (Concatenate)   (None, 26, 26, 180)  0           concatenate_193[0][0]            \n",
            "                                                                 dropout_203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 26, 26, 180)  720         concatenate_194[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 26, 26, 180)  0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 26, 26, 24)   4320        activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 26, 26, 24)   96          conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 26, 26, 24)   0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 26, 26, 12)   2592        activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 26, 26, 12)   0           conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_195 (Concatenate)   (None, 26, 26, 192)  0           concatenate_194[0][0]            \n",
            "                                                                 dropout_204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 26, 26, 192)  768         concatenate_195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 26, 26, 192)  0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 26, 26, 24)   4608        activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 26, 26, 24)   96          conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 26, 26, 24)   0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 26, 26, 12)   2592        activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 26, 26, 12)   0           conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_196 (Concatenate)   (None, 26, 26, 204)  0           concatenate_195[0][0]            \n",
            "                                                                 dropout_205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 26, 26, 204)  816         concatenate_196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 26, 26, 204)  0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 26, 26, 12)   2448        activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 26, 26, 12)   0           conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 13, 13, 12)   0           dropout_206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 13, 13, 12)   48          average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 13, 13, 12)   0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 13, 13, 24)   288         activation_406[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 13, 13, 24)   96          conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 13, 13, 24)   0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 13, 13, 12)   2592        activation_407[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 13, 13, 12)   0           conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_197 (Concatenate)   (None, 13, 13, 24)   0           average_pooling2d_13[0][0]       \n",
            "                                                                 dropout_207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 13, 13, 24)   96          concatenate_197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 13, 13, 24)   0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 13, 13, 24)   576         activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 13, 13, 24)   96          conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 13, 13, 24)   0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 13, 13, 12)   2592        activation_409[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 13, 13, 12)   0           conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_198 (Concatenate)   (None, 13, 13, 36)   0           concatenate_197[0][0]            \n",
            "                                                                 dropout_208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 13, 13, 36)   144         concatenate_198[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 13, 13, 36)   0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 13, 13, 24)   864         activation_410[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 13, 13, 24)   96          conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 13, 13, 24)   0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 13, 13, 12)   2592        activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 13, 13, 12)   0           conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_199 (Concatenate)   (None, 13, 13, 48)   0           concatenate_198[0][0]            \n",
            "                                                                 dropout_209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 13, 13, 48)   192         concatenate_199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 13, 13, 48)   0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 13, 13, 24)   1152        activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 13, 13, 24)   96          conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 13, 13, 24)   0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 13, 13, 12)   2592        activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_210 (Dropout)           (None, 13, 13, 12)   0           conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_200 (Concatenate)   (None, 13, 13, 60)   0           concatenate_199[0][0]            \n",
            "                                                                 dropout_210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 13, 13, 60)   240         concatenate_200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 13, 13, 60)   0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 13, 13, 24)   1440        activation_414[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 13, 13, 24)   96          conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 13, 13, 24)   0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 13, 13, 12)   2592        activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 13, 13, 12)   0           conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_201 (Concatenate)   (None, 13, 13, 72)   0           concatenate_200[0][0]            \n",
            "                                                                 dropout_211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 13, 13, 72)   288         concatenate_201[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 13, 13, 72)   0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 13, 13, 24)   1728        activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 13, 13, 24)   96          conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 13, 13, 24)   0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 13, 13, 12)   2592        activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 13, 13, 12)   0           conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_202 (Concatenate)   (None, 13, 13, 84)   0           concatenate_201[0][0]            \n",
            "                                                                 dropout_212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 13, 13, 84)   336         concatenate_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 13, 13, 84)   0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 13, 13, 24)   2016        activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 13, 13, 24)   96          conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 13, 13, 24)   0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 13, 13, 12)   2592        activation_419[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 13, 13, 12)   0           conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_203 (Concatenate)   (None, 13, 13, 96)   0           concatenate_202[0][0]            \n",
            "                                                                 dropout_213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 13, 13, 96)   384         concatenate_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 13, 13, 96)   0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 13, 13, 24)   2304        activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 13, 13, 24)   96          conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 13, 13, 24)   0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 13, 13, 12)   2592        activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 13, 13, 12)   0           conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_204 (Concatenate)   (None, 13, 13, 108)  0           concatenate_203[0][0]            \n",
            "                                                                 dropout_214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 13, 13, 108)  432         concatenate_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 13, 13, 108)  0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 13, 13, 24)   2592        activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 13, 13, 24)   96          conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 13, 13, 24)   0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 13, 13, 12)   2592        activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 13, 13, 12)   0           conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_205 (Concatenate)   (None, 13, 13, 120)  0           concatenate_204[0][0]            \n",
            "                                                                 dropout_215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 13, 13, 120)  480         concatenate_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 13, 13, 120)  0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 13, 13, 24)   2880        activation_424[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 13, 13, 24)   96          conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 13, 13, 24)   0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 13, 13, 12)   2592        activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 13, 13, 12)   0           conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_206 (Concatenate)   (None, 13, 13, 132)  0           concatenate_205[0][0]            \n",
            "                                                                 dropout_216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 13, 13, 132)  528         concatenate_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 13, 13, 132)  0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 13, 13, 24)   3168        activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 13, 13, 24)   96          conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 13, 13, 24)   0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 13, 13, 12)   2592        activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 13, 13, 12)   0           conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_207 (Concatenate)   (None, 13, 13, 144)  0           concatenate_206[0][0]            \n",
            "                                                                 dropout_217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 13, 13, 144)  576         concatenate_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 13, 13, 144)  0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 13, 13, 24)   3456        activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_429 (BatchN (None, 13, 13, 24)   96          conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 13, 13, 24)   0           batch_normalization_429[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 13, 13, 12)   2592        activation_429[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 13, 13, 12)   0           conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_208 (Concatenate)   (None, 13, 13, 156)  0           concatenate_207[0][0]            \n",
            "                                                                 dropout_218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_430 (BatchN (None, 13, 13, 156)  624         concatenate_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 13, 13, 156)  0           batch_normalization_430[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 13, 13, 24)   3744        activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_431 (BatchN (None, 13, 13, 24)   96          conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 13, 13, 24)   0           batch_normalization_431[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 13, 13, 12)   2592        activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 13, 13, 12)   0           conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_209 (Concatenate)   (None, 13, 13, 168)  0           concatenate_208[0][0]            \n",
            "                                                                 dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_432 (BatchN (None, 13, 13, 168)  672         concatenate_209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 13, 13, 168)  0           batch_normalization_432[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 13, 13, 24)   4032        activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_433 (BatchN (None, 13, 13, 24)   96          conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 13, 13, 24)   0           batch_normalization_433[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 13, 13, 12)   2592        activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 13, 13, 12)   0           conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_210 (Concatenate)   (None, 13, 13, 180)  0           concatenate_209[0][0]            \n",
            "                                                                 dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_434 (BatchN (None, 13, 13, 180)  720         concatenate_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 13, 13, 180)  0           batch_normalization_434[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 13, 13, 24)   4320        activation_434[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_435 (BatchN (None, 13, 13, 24)   96          conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 13, 13, 24)   0           batch_normalization_435[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 13, 13, 12)   2592        activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 13, 13, 12)   0           conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_211 (Concatenate)   (None, 13, 13, 192)  0           concatenate_210[0][0]            \n",
            "                                                                 dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_436 (BatchN (None, 13, 13, 192)  768         concatenate_211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 13, 13, 192)  0           batch_normalization_436[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 13, 13, 24)   4608        activation_436[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_437 (BatchN (None, 13, 13, 24)   96          conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 13, 13, 24)   0           batch_normalization_437[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 13, 13, 12)   2592        activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 13, 13, 12)   0           conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_212 (Concatenate)   (None, 13, 13, 204)  0           concatenate_211[0][0]            \n",
            "                                                                 dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_438 (BatchN (None, 13, 13, 204)  816         concatenate_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 13, 13, 204)  0           batch_normalization_438[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 13, 13, 12)   2448        activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 13, 13, 12)   0           conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 6, 6, 12)     0           dropout_223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_439 (BatchN (None, 6, 6, 12)     48          average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 6, 6, 12)     0           batch_normalization_439[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 6, 6, 24)     288         activation_439[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_440 (BatchN (None, 6, 6, 24)     96          conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 6, 6, 24)     0           batch_normalization_440[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 6, 6, 12)     2592        activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_224 (Dropout)           (None, 6, 6, 12)     0           conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_213 (Concatenate)   (None, 6, 6, 24)     0           average_pooling2d_14[0][0]       \n",
            "                                                                 dropout_224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_441 (BatchN (None, 6, 6, 24)     96          concatenate_213[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 6, 6, 24)     0           batch_normalization_441[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 6, 6, 24)     576         activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_442 (BatchN (None, 6, 6, 24)     96          conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 6, 6, 24)     0           batch_normalization_442[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 6, 6, 12)     2592        activation_442[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_225 (Dropout)           (None, 6, 6, 12)     0           conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_214 (Concatenate)   (None, 6, 6, 36)     0           concatenate_213[0][0]            \n",
            "                                                                 dropout_225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_443 (BatchN (None, 6, 6, 36)     144         concatenate_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 6, 6, 36)     0           batch_normalization_443[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 6, 6, 24)     864         activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_444 (BatchN (None, 6, 6, 24)     96          conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 6, 6, 24)     0           batch_normalization_444[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 6, 6, 12)     2592        activation_444[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_226 (Dropout)           (None, 6, 6, 12)     0           conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_215 (Concatenate)   (None, 6, 6, 48)     0           concatenate_214[0][0]            \n",
            "                                                                 dropout_226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_445 (BatchN (None, 6, 6, 48)     192         concatenate_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 6, 6, 48)     0           batch_normalization_445[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 6, 6, 24)     1152        activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_446 (BatchN (None, 6, 6, 24)     96          conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 6, 6, 24)     0           batch_normalization_446[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 6, 6, 12)     2592        activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 6, 6, 12)     0           conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_216 (Concatenate)   (None, 6, 6, 60)     0           concatenate_215[0][0]            \n",
            "                                                                 dropout_227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_447 (BatchN (None, 6, 6, 60)     240         concatenate_216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 6, 6, 60)     0           batch_normalization_447[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 6, 6, 24)     1440        activation_447[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_448 (BatchN (None, 6, 6, 24)     96          conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 6, 6, 24)     0           batch_normalization_448[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 6, 6, 12)     2592        activation_448[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_228 (Dropout)           (None, 6, 6, 12)     0           conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_217 (Concatenate)   (None, 6, 6, 72)     0           concatenate_216[0][0]            \n",
            "                                                                 dropout_228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_449 (BatchN (None, 6, 6, 72)     288         concatenate_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 6, 6, 72)     0           batch_normalization_449[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 6, 6, 24)     1728        activation_449[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_450 (BatchN (None, 6, 6, 24)     96          conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 6, 6, 24)     0           batch_normalization_450[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 6, 6, 12)     2592        activation_450[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_229 (Dropout)           (None, 6, 6, 12)     0           conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_218 (Concatenate)   (None, 6, 6, 84)     0           concatenate_217[0][0]            \n",
            "                                                                 dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_451 (BatchN (None, 6, 6, 84)     336         concatenate_218[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 6, 6, 84)     0           batch_normalization_451[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 6, 6, 24)     2016        activation_451[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_452 (BatchN (None, 6, 6, 24)     96          conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 6, 6, 24)     0           batch_normalization_452[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 6, 6, 12)     2592        activation_452[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_230 (Dropout)           (None, 6, 6, 12)     0           conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_219 (Concatenate)   (None, 6, 6, 96)     0           concatenate_218[0][0]            \n",
            "                                                                 dropout_230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_453 (BatchN (None, 6, 6, 96)     384         concatenate_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 6, 6, 96)     0           batch_normalization_453[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 6, 6, 24)     2304        activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_454 (BatchN (None, 6, 6, 24)     96          conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 6, 6, 24)     0           batch_normalization_454[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 6, 6, 12)     2592        activation_454[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_231 (Dropout)           (None, 6, 6, 12)     0           conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_220 (Concatenate)   (None, 6, 6, 108)    0           concatenate_219[0][0]            \n",
            "                                                                 dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_455 (BatchN (None, 6, 6, 108)    432         concatenate_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 6, 6, 108)    0           batch_normalization_455[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 6, 6, 24)     2592        activation_455[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_456 (BatchN (None, 6, 6, 24)     96          conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 6, 6, 24)     0           batch_normalization_456[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 6, 6, 12)     2592        activation_456[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_232 (Dropout)           (None, 6, 6, 12)     0           conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_221 (Concatenate)   (None, 6, 6, 120)    0           concatenate_220[0][0]            \n",
            "                                                                 dropout_232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_457 (BatchN (None, 6, 6, 120)    480         concatenate_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 6, 6, 120)    0           batch_normalization_457[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 6, 6, 24)     2880        activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_458 (BatchN (None, 6, 6, 24)     96          conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 6, 6, 24)     0           batch_normalization_458[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 6, 6, 12)     2592        activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_233 (Dropout)           (None, 6, 6, 12)     0           conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_222 (Concatenate)   (None, 6, 6, 132)    0           concatenate_221[0][0]            \n",
            "                                                                 dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_459 (BatchN (None, 6, 6, 132)    528         concatenate_222[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 6, 6, 132)    0           batch_normalization_459[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 6, 6, 24)     3168        activation_459[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_460 (BatchN (None, 6, 6, 24)     96          conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 6, 6, 24)     0           batch_normalization_460[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 6, 6, 12)     2592        activation_460[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_234 (Dropout)           (None, 6, 6, 12)     0           conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_223 (Concatenate)   (None, 6, 6, 144)    0           concatenate_222[0][0]            \n",
            "                                                                 dropout_234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_461 (BatchN (None, 6, 6, 144)    576         concatenate_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 6, 6, 144)    0           batch_normalization_461[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 6, 6, 24)     3456        activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_462 (BatchN (None, 6, 6, 24)     96          conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 6, 6, 24)     0           batch_normalization_462[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 6, 6, 12)     2592        activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_235 (Dropout)           (None, 6, 6, 12)     0           conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_224 (Concatenate)   (None, 6, 6, 156)    0           concatenate_223[0][0]            \n",
            "                                                                 dropout_235[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_463 (BatchN (None, 6, 6, 156)    624         concatenate_224[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 6, 6, 156)    0           batch_normalization_463[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 6, 6, 24)     3744        activation_463[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_464 (BatchN (None, 6, 6, 24)     96          conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 6, 6, 24)     0           batch_normalization_464[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 6, 6, 12)     2592        activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_236 (Dropout)           (None, 6, 6, 12)     0           conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_225 (Concatenate)   (None, 6, 6, 168)    0           concatenate_224[0][0]            \n",
            "                                                                 dropout_236[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_465 (BatchN (None, 6, 6, 168)    672         concatenate_225[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 6, 6, 168)    0           batch_normalization_465[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 6, 6, 24)     4032        activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_466 (BatchN (None, 6, 6, 24)     96          conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 6, 6, 24)     0           batch_normalization_466[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 6, 6, 12)     2592        activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_237 (Dropout)           (None, 6, 6, 12)     0           conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_226 (Concatenate)   (None, 6, 6, 180)    0           concatenate_225[0][0]            \n",
            "                                                                 dropout_237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_467 (BatchN (None, 6, 6, 180)    720         concatenate_226[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 6, 6, 180)    0           batch_normalization_467[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 6, 6, 24)     4320        activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_468 (BatchN (None, 6, 6, 24)     96          conv2d_468[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 6, 6, 24)     0           batch_normalization_468[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_469 (Conv2D)             (None, 6, 6, 12)     2592        activation_468[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_238 (Dropout)           (None, 6, 6, 12)     0           conv2d_469[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_227 (Concatenate)   (None, 6, 6, 192)    0           concatenate_226[0][0]            \n",
            "                                                                 dropout_238[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_469 (BatchN (None, 6, 6, 192)    768         concatenate_227[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 6, 6, 192)    0           batch_normalization_469[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_470 (Conv2D)             (None, 6, 6, 24)     4608        activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_470 (BatchN (None, 6, 6, 24)     96          conv2d_470[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 6, 6, 24)     0           batch_normalization_470[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, 6, 6, 12)     2592        activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_239 (Dropout)           (None, 6, 6, 12)     0           conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_228 (Concatenate)   (None, 6, 6, 204)    0           concatenate_227[0][0]            \n",
            "                                                                 dropout_239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_471 (BatchN (None, 6, 6, 204)    816         concatenate_228[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 6, 6, 204)    0           batch_normalization_471[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, 6, 6, 12)     2448        activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_240 (Dropout)           (None, 6, 6, 12)     0           conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 3, 3, 12)     0           dropout_240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_472 (BatchN (None, 3, 3, 12)     48          average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 3, 3, 12)     0           batch_normalization_472[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, 3, 3, 24)     288         activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_473 (BatchN (None, 3, 3, 24)     96          conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 3, 3, 24)     0           batch_normalization_473[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, 3, 3, 12)     2592        activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_241 (Dropout)           (None, 3, 3, 12)     0           conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_229 (Concatenate)   (None, 3, 3, 24)     0           average_pooling2d_15[0][0]       \n",
            "                                                                 dropout_241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_474 (BatchN (None, 3, 3, 24)     96          concatenate_229[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 3, 3, 24)     0           batch_normalization_474[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, 3, 3, 24)     576         activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_475 (BatchN (None, 3, 3, 24)     96          conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, 3, 3, 24)     0           batch_normalization_475[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, 3, 3, 12)     2592        activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_242 (Dropout)           (None, 3, 3, 12)     0           conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_230 (Concatenate)   (None, 3, 3, 36)     0           concatenate_229[0][0]            \n",
            "                                                                 dropout_242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, 3, 3, 36)     144         concatenate_230[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 3, 3, 36)     0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, 3, 3, 24)     864         activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, 3, 3, 24)     96          conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 3, 3, 24)     0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, 3, 3, 12)     2592        activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_243 (Dropout)           (None, 3, 3, 12)     0           conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_231 (Concatenate)   (None, 3, 3, 48)     0           concatenate_230[0][0]            \n",
            "                                                                 dropout_243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, 3, 3, 48)     192         concatenate_231[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 3, 3, 48)     0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, 3, 3, 24)     1152        activation_478[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, 3, 3, 24)     96          conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 3, 3, 24)     0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, 3, 3, 12)     2592        activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_244 (Dropout)           (None, 3, 3, 12)     0           conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_232 (Concatenate)   (None, 3, 3, 60)     0           concatenate_231[0][0]            \n",
            "                                                                 dropout_244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, 3, 3, 60)     240         concatenate_232[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 3, 3, 60)     0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, 3, 3, 24)     1440        activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, 3, 3, 24)     96          conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 3, 3, 24)     0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, 3, 3, 12)     2592        activation_481[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_245 (Dropout)           (None, 3, 3, 12)     0           conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_233 (Concatenate)   (None, 3, 3, 72)     0           concatenate_232[0][0]            \n",
            "                                                                 dropout_245[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, 3, 3, 72)     288         concatenate_233[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 3, 3, 72)     0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, 3, 3, 24)     1728        activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, 3, 3, 24)     96          conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 3, 3, 24)     0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, 3, 3, 12)     2592        activation_483[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_246 (Dropout)           (None, 3, 3, 12)     0           conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_234 (Concatenate)   (None, 3, 3, 84)     0           concatenate_233[0][0]            \n",
            "                                                                 dropout_246[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, 3, 3, 84)     336         concatenate_234[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 3, 3, 84)     0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, 3, 3, 24)     2016        activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, 3, 3, 24)     96          conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 3, 3, 24)     0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, 3, 3, 12)     2592        activation_485[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_247 (Dropout)           (None, 3, 3, 12)     0           conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_235 (Concatenate)   (None, 3, 3, 96)     0           concatenate_234[0][0]            \n",
            "                                                                 dropout_247[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, 3, 3, 96)     384         concatenate_235[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 3, 3, 96)     0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, 3, 3, 24)     2304        activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, 3, 3, 24)     96          conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 3, 3, 24)     0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, 3, 3, 12)     2592        activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_248 (Dropout)           (None, 3, 3, 12)     0           conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_236 (Concatenate)   (None, 3, 3, 108)    0           concatenate_235[0][0]            \n",
            "                                                                 dropout_248[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, 3, 3, 108)    432         concatenate_236[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 3, 3, 108)    0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 3, 3, 24)     2592        activation_488[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, 3, 3, 24)     96          conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 3, 3, 24)     0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 3, 3, 12)     2592        activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_249 (Dropout)           (None, 3, 3, 12)     0           conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_237 (Concatenate)   (None, 3, 3, 120)    0           concatenate_236[0][0]            \n",
            "                                                                 dropout_249[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, 3, 3, 120)    480         concatenate_237[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 3, 3, 120)    0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 3, 3, 24)     2880        activation_490[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, 3, 3, 24)     96          conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 3, 3, 24)     0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 3, 3, 12)     2592        activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_250 (Dropout)           (None, 3, 3, 12)     0           conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_238 (Concatenate)   (None, 3, 3, 132)    0           concatenate_237[0][0]            \n",
            "                                                                 dropout_250[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, 3, 3, 132)    528         concatenate_238[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 3, 3, 132)    0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 3, 3, 24)     3168        activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, 3, 3, 24)     96          conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 3, 3, 24)     0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 3, 3, 12)     2592        activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_251 (Dropout)           (None, 3, 3, 12)     0           conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_239 (Concatenate)   (None, 3, 3, 144)    0           concatenate_238[0][0]            \n",
            "                                                                 dropout_251[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, 3, 3, 144)    576         concatenate_239[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 3, 3, 144)    0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 3, 3, 24)     3456        activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, 3, 3, 24)     96          conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 3, 3, 24)     0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 3, 3, 12)     2592        activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_252 (Dropout)           (None, 3, 3, 12)     0           conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_240 (Concatenate)   (None, 3, 3, 156)    0           concatenate_239[0][0]            \n",
            "                                                                 dropout_252[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, 3, 3, 156)    624         concatenate_240[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 3, 3, 156)    0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 1, 1, 156)    0           activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 156)          0           average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           1570        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 336,886\n",
            "Trainable params: 320,806\n",
            "Non-trainable params: 16,080\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a4aa8818828844c3c353d304c2dd84b2b3e68024",
        "scrolled": true,
        "id": "rKzyRUhAZTh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1070
        },
        "outputId": "c6bd877d-8429-442c-8462-d7dc086f94d7"
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "hs=model_small.fit(x_train, y_train, batch_size=batch_size,verbose=1,\n",
        "                    epochs=model_small_epochs, callbacks=callbacks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "model_small.save(model_file)\n",
        "print('Saved model_small to disk')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "   256/100000 [..............................] - ETA: 2:20:33 - loss: 2.5954 - acc: 0.1055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.486633). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100000/100000 [==============================] - 393s 4ms/step - loss: 1.6358 - acc: 0.3963 - val_loss: 1.5060 - val_acc: 0.4789\n",
            "Epoch 2/20\n",
            "  7168/100000 [=>............................] - ETA: 5:34 - loss: 1.4000 - acc: 0.4851"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-fb7d5466cf84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hs=model_small.fit(x_train, y_train, batch_size=batch_size,verbose=1,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_small_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_small\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved model_small to disk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-2n8nEtKZTiG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "86607351bf8f2b7358482e908fe190924650691a",
        "id": "0Xbip-prZTiR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('====================END OF SMALLER MODEL====================')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "80cc5c901ceb489ffb260bff35d50ee9af6b1826",
        "id": "Xpt3tqQVZTil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('====================BEGIN OF LARGER MODEL====================')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7c17f4244c917e97e7cc1557ae60bce8dba7e47e",
        "id": "Guts0TXcZTiu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "x_train, y_train, x_test, y_test = load_data(resize=False)\n",
        "#callbacks\n",
        "model_checkpointer=ModelCheckpoint('large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',\n",
        "                verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "# early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "clr = CyclicLR(base_lr=0.1, max_lr=0.2,step_size=8*(len(y_train)/batch_size),mode='exp_range',gamma=0.99994)\n",
        "\n",
        "# M = 6\n",
        "# nb_epoch = T = 200\n",
        "# alpha_zero = 0.1\n",
        "# model_prefix = 'ensemble_'\n",
        "# snapshot = SnapshotCallbackBuilder(T, M, alpha_zero) \n",
        "# callbacks = snapshot.get_callbacks(model_prefix=model_prefix)\n",
        "\n",
        "callbacks = [clr, model_checkpointer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5f3adc0c3037f0d323cda32709d8abd57602b3c3",
        "id": "-K5vbFZyZTi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model_prev=load_prev_model(model_small)\n",
        "model_large = create_model(x_train.shape[1:],num_layers=layers_large)\n",
        "# model_large = larger_model(model_prev)\n",
        "copy_weights(model_large,model_prev)\n",
        "model_large.compile(loss='categorical_crossentropy',metrics=['accuracy'],\n",
        "                    optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True))\n",
        "model_large.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "53b7ed0b0e8acefefda51802f0bd74f0cace4c72",
        "id": "9o2OweZKZTjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "hl=model_large.fit(x_train, y_train, batch_size=batch_size, verbose=1,\n",
        "                epochs=model_large_epochs1, callbacks=callbacks,\n",
        "                validation_data=(x_test, y_test))\n",
        "model_large.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b0sXWRg2ZTjT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_fyYHI99ZTjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#callbacks\n",
        "model_checkpointer=ModelCheckpoint('large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',\n",
        "                verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "# early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "clr = CyclicLR(base_lr=0.001, max_lr=0.3,step_size=6*(len(y_train)/batch_size),mode='triangular2',gamma=0.99994)\n",
        "#aggresively decrease lr\n",
        "\n",
        "# M = 6\n",
        "# nb_epoch = T = 200\n",
        "# alpha_zero = 0.1\n",
        "# model_prefix = 'ensemble_'\n",
        "# snapshot = SnapshotCallbackBuilder(T, M, alpha_zero) \n",
        "\n",
        "\n",
        "# callbacks = snapshot.get_callbacks(model_prefix=model_prefix)\n",
        "callbacks = [clr, model_checkpointer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRmazhXkZTjj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "hl2=model_large.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=model_large_epochs1,\n",
        "                epochs=model_large_epochs1+model_large_epochs2, callbacks=callbacks,\n",
        "                validation_data=(x_test, y_test))\n",
        "model_large.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQXXbiQwZTjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = load_data(resize=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zp8jJaG4ZTj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_checkpointer=ModelCheckpoint('large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',\n",
        "                verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.001, max_lr=0.006,step_size=8*(len(y_train)/batch_size),mode='triangular')\n",
        "#start increasing lr since model has begun to overfit\n",
        "callbacks = [clr, model_checkpointer]\n",
        "model_large_2=load_model('large_weights.112-0.87.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J17uipNLZTkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "hl3=model_large_2.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=117,\n",
        "                epochs=model_large_epochs1+model_large_epochs2, callbacks=callbacks,\n",
        "                validation_data=(x_test, y_test))\n",
        "model_large.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7be8a1352f65787da27dc9eeb8b9073890561062",
        "id": "NjnvEpbZZTkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model_large.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6151d97fb488aed1553bb9ae29fcb9e3e0bf1f08",
        "id": "V7sFOSWBZTkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('====================END OF LARGER MODEL====================')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-CYRFvb_ZTka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model_large.evaluate(x_test, y_test, verbose=1)\n",
        "s=open('res.txt','w')\n",
        "s.write(score[0],score[1])\n",
        "s.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jqwCJ6A5ZTkh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s=open('res.txt','a')\n",
        "s.write(str(hl))\n",
        "s.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzkjsZiyZTko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xf4BkAzZTkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}