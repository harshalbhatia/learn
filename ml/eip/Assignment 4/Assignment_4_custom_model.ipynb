{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-4-custom_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "f67729355a01c19c62bfa2145d9594b1da821fc6",
        "id": "AbFZ1CPnyLEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q six numpy scipy matplotlib scikit-image opencv-python imageio\n",
        "!pip install -q keras imgaug\n",
        "!pip install -q tensorboardcolab\n",
        "!pip install -q git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "jwLq5vZ1yLE_",
        "colab_type": "code",
        "outputId": "f8327f27-0920-48c9-d611-d0f883a393fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras_contrib.callbacks import CyclicLR, DeadReluDetector, SnapshotCallbackBuilder, SnapshotModelCheckpoint\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "from keras_contrib.applications import DenseNet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "363049cf0704e0aebfa7ea4994c6c291fd66cbac",
        "id": "uEbrjMRqyLFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation,LeakyReLU\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,SeparableConv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
        "# from keras.callbacks import LearningRateScheduler,ModelCheckpoint,EarlyStopping,LambdaCallback\n",
        "import os,sys,math\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22f446b53ec82f3244c33dd780ab24b896178cf9",
        "id": "HGIF2j6YyLFc",
        "colab_type": "code",
        "outputId": "02426a3b-730a-4015-bb42-53cc71309ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "cell_type": "code",
      "source": [
        "import google\n",
        "colab_dir='./'\n",
        "file_name='EIP_CIFAR_10'\n",
        "if hasattr(google,'colab'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    colab_dir='/content/gdrive/My Drive/Colab Notebooks/'\n",
        "model_file=colab_dir+file_name+'.h5'\n",
        "weights_dir=colab_dir+'weights/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "beylEPLZyLFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "slwWCSvnqR2C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/pjreddie/darknet.git dkn\n",
        "# !mv -v dkn/* ./\n",
        "# !sed -i  's/GPU=0/GPU=1/g' Makefile\n",
        "# !make -j4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zKvvOwUXrbQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !wget https://www.hublot.com/images/News_2018/match_for_solidarity_gallery_13.jpg -O input_image.jpg\n",
        "# !wget https://pjreddie.com/media/files/yolov2-tiny.weights -O y.weights\n",
        "# !wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov2-tiny.cfg -O y.cfg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6oyNo4br4XF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !./darknet detect y.cfg y.weights input_image.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa9bb45cb7f0171c15c4b065ade989e82042b15a",
        "id": "VKufdLiEyLFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Augmentation and resizing\n",
        "#augment and then concat samples with original\n",
        "def augment(dataset,flip=0.5,blur=1.0):\n",
        "    ia.seed(1)\n",
        "    seq = iaa.Sequential([iaa.Crop(px=(0, 16)),iaa.Fliplr(0.5),iaa.GaussianBlur(sigma=(0, 3.0))], random_order=True)   \n",
        "    return seq.augment_images(dataset)\n",
        "\n",
        "def augmenter(X,y,start=0,end=1,append=False):\n",
        "    ln=len(X)\n",
        "    print('Before augmentation:',X.shape,y.shape)\n",
        "    start=int(start*ln)\n",
        "    end=int(end*ln)\n",
        "    if append:\n",
        "      new_X=augment(X)[start:end]\n",
        "      new_y=y[start:end]\n",
        "      X=np.concatenate((X,new_X))\n",
        "      y=np.concatenate((y,new_y))\n",
        "    else:\n",
        "      X=augment(X)\n",
        "    print('After augmentation:',X.shape,y.shape)\n",
        "    return (X,y)\n",
        "\n",
        "#26x26 is almost half of 32x32. 22x22 maybe too small even though its exact half.\n",
        "def resize_imgs(imgs,shape=(26,26)):\n",
        "    seq = iaa.Sequential([iaa.Scale({\"height\": shape[0], \"width\": shape[1]})])\n",
        "    return seq.augment_images(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d5f083dfa8904a9bd7433e385ad2a0b8a236b22",
        "id": "Zw3sldJUyLGg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modval=50\n",
        "max_lr=0.1\n",
        "\n",
        "def cosine_anneal_schedule(t,lr):\n",
        "  global modval,max_lr\n",
        "  modval=int(modval)\n",
        "  cos_inner = (np.pi * (t % modval))/ modval\n",
        "  cos_out = np.cos(cos_inner) + 1\n",
        "  return float(max_lr / 2 * cos_out)\n",
        "\n",
        "def load_prev_model(model_small=None):\n",
        "#     print(os.popen('du -sh '+colab_dir+'*').read())\n",
        "    last_best=os.popen('du -sh '+colab_dir+r'*|sed -r \"s/^[0-9\\.]+[MK]?\\s(.*)$/\\1/g;\"|tail -1').read().strip()\n",
        "    model_prev=None\n",
        "    try:\n",
        "        print('Attempting to load last best model from file - ',end='')\n",
        "        last_best_fn=last_best.split('/')[-1]\n",
        "        last_best_epoch=last_best_fn.split('.')[1].split('-')[0]\n",
        "        model_prev=load_model(last_best)\n",
        "        print('Sucess\\nLoaded '+last_best_fn, 'epoch :', last_best_epoch)\n",
        "    except Exception as e:\n",
        "        print('Failed!\\n',e)\n",
        "        try:\n",
        "            print('Attempting to load last saved model from file - ',end='')\n",
        "            model_prev = load_model(model_file)\n",
        "            print('Sucess\\nLoaded model from file',model_file)\n",
        "        except Exception as e:\n",
        "    #         print(str(e), 'at line ', sys.exc_info()[2].tb_lineno)\n",
        "            print('Failed!\\n',e)\n",
        "            try:\n",
        "                print('Attempting to load in memory, small model - ',end='')\n",
        "                if len(model_small.layers)>1:\n",
        "                    model_prev=model_small\n",
        "                print('Sucess')\n",
        "            except Exception as e:\n",
        "                print('Failed!\\n',e)\n",
        "    return model_prev\n",
        "  \n",
        "def copy_weights(model_to,model_from):\n",
        "    #model_to.set_weights(model_from.get_weights())\n",
        "    s,err=0,0\n",
        "    print('Trying to copy weights')\n",
        "    try:\n",
        "        if len(model_to.layers) >1 and len(model_from.layers) >1:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        print('Inavlid models',model_to,model_from)\n",
        "        return\n",
        "    for new_layer, layer in zip(model_to.layers[1:], model_from.layers[1:]):\n",
        "        s+=1\n",
        "        try:\n",
        "            new_layer.set_weights(layer.get_weights())\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    print('Done: errors:',err)\n",
        "      \n",
        "#new model with larger i/p layer\n",
        "def larger_model(src_model,shape=(32,32,3)):\n",
        "    new_input=Input(shape)\n",
        "    src_model.layers.pop(0)\n",
        "    new_output=src_model(new_input)\n",
        "    new_model=Model(new_input,new_output)\n",
        "    return new_model\n",
        "\n",
        "# Load CIFAR10 Data\n",
        "def load_data(resize=False,append=False,shape=(26,26),train_augment=True,test_augment=False):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    \n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    if resize:\n",
        "        x_train=resize_imgs(x_train,shape)\n",
        "        x_test=resize_imgs(x_test,shape)\n",
        "    if train_augment:\n",
        "      (x_train, y_train) = augmenter(x_train, y_train,end=1,append=append)\n",
        "    if test_augment:\n",
        "        (x_test, y_test) = augmenter(x_test, y_test,end=1,append=append)\n",
        "    return (x_train, y_train,x_test, y_test)\n",
        "#create a dnn model\n",
        "def create_model(input_shape,num_layers,input_conv_filters=12,input=None):\n",
        "    print('Creating model with input shape',input_shape)\n",
        "    if input is None:\n",
        "        input = Input(input_shape)\n",
        "    First_Conv2D = Conv2D(input_conv_filters, (3,3), use_bias=False ,padding='same')(input)\n",
        "    hidden_dense_blocks = dense_units_chain(n_dense_blocks,First_Conv2D,num_filter,dropout_rate,num_layers)\n",
        "    Last_Block = add_denseblock(hidden_dense_blocks, num_filter, dropout_rate)\n",
        "    output = output_layer(Last_Block)\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5QrXF2BznZs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import GlobalAveragePooling2D\n",
        "sc=False\n",
        "# Dense Block\n",
        "def add_denseblock(input,num_layers, growth_rate = 12, dropout_rate = 0.2,bn_layers=48,middle_layers=24):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(num_layers):\n",
        "        ######################################################################################################################################\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)        \n",
        "        Conv2D_1_1_bottleneck = Conv2D(bn_layers, (1,1), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #bottleneck  <===\n",
        "        ###################################################################################################################################### |\n",
        "        BatchNorm = BatchNormalization()(Conv2D_1_1_bottleneck) #extra layer                                                                 # |\n",
        "        relu = Activation('relu')(BatchNorm) #extra layer                                                                                    # |\n",
        "        Conv2D_1_1 = Conv2D(middle_layers, (1,1), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #extra layer          # |\n",
        "        ###################################################################################################################################### |\n",
        "        BatchNorm = BatchNormalization()(Conv2D_1_1) #bottleneck   <================================================================\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(growth_rate, (3,3), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu)\n",
        "        ######################################################################################################################################|\n",
        "        \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg\n",
        "\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    GlobalAveragePooling = GlobalAveragePooling2D(data_format='channels_last')(relu)\n",
        "#     flat = Flatten()(GlobalAveragePooling)\n",
        "    output = Dense(num_classes, activation='softmax')(GlobalAveragePooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SizS-NnKfkQf",
        "colab_type": "code",
        "outputId": "47f2d20f-2f36-4d23-ad81-b176117287e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "num_filter = 0 # add it up as you go\n",
        "compression = 0.5\n",
        "dropout_rate =0.2#0.2#.5\n",
        "num_classes = 10\n",
        "\n",
        "modval=20\n",
        "max_lr=0.3\n",
        "\n",
        "layer_models=[[96,48,24],[48,24,12]]\n",
        "layer_models_index=1\n",
        "bn_layers,middle_layers,growth_rate=layer_models[layer_models_index]\n",
        "print('bn,middle,k :',layer_models[layer_models_index])\n",
        "# num_layers=8 is kinda eq of standard Densenet-BC L=40 where 12*2 i.e 12*(BN_RELU_CONV*2), here its 8*3 i.e 8*(BN_RELU_CONV*3) \n",
        "num_layers=16#16#15\n",
        "batch_size=64\n",
        "initial_layers=12#12\n",
        "hist=[]\n",
        "keras_model=False\n",
        "epochs=initial_epoch=0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bn,middle,k : [48, 24, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWb3CVJPz6_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=None\n",
        "if keras_model:\n",
        "  model=DenseNet(input_shape=(32,32,3),depth=100,nb_dense_block=3,growth_rate=12,nb_filter=-1,bottleneck=True,reduction=0.5,dropout_rate=0.5,classes=10,pooling='avg')\n",
        "else:\n",
        "  input = Input(shape=(32, 32, 3,))\n",
        "  First_Conv2D = Conv2D(initial_layers, (3,3), use_bias=False ,padding='same')(input)\n",
        "  num_filter=initial_layers\n",
        "  \n",
        "  First_Block = add_denseblock(First_Conv2D,num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "  num_filter+=growth_rate*num_layers\n",
        "  First_Transition = add_transition(First_Block, growth_rate*2, dropout_rate)\n",
        "  num_filter=num_filter//2\n",
        "  Second_Block = add_denseblock(First_Transition, num_layers,growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "  num_filter+=growth_rate*num_layers\n",
        "  Second_Transition = add_transition(Second_Block, growth_rate*2, dropout_rate)\n",
        "  num_filter=num_filter//2\n",
        "  \n",
        "  Third_Block = add_denseblock(Second_Transition,num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "  num_filter+=growth_rate*num_layers\n",
        "  Third_Transition = add_transition(Third_Block, growth_rate*2, dropout_rate)\n",
        "  \n",
        "  Last_Block = add_denseblock(Third_Transition, num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "  output = output_layer(Third_Block)\n",
        "  model = Model(inputs=[input], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S0I-BnZt6mCg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tbc=TensorBoardColabCallback(TensorBoardColab())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnCBJrCs11vl",
        "colab_type": "code",
        "outputId": "df7dd456-46a3-47ef-adbe-46cd4565f0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 21734
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_540 (Conv2D)             (None, 32, 32, 12)   324         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_540 (BatchN (None, 32, 32, 12)   48          conv2d_540[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_540 (Activation)     (None, 32, 32, 12)   0           batch_normalization_540[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_541 (Conv2D)             (None, 32, 32, 48)   576         activation_540[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_541 (BatchN (None, 32, 32, 48)   192         conv2d_541[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_541 (Activation)     (None, 32, 32, 48)   0           batch_normalization_541[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_542 (Conv2D)             (None, 32, 32, 24)   1152        activation_541[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_542 (BatchN (None, 32, 32, 24)   96          conv2d_542[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_542 (Activation)     (None, 32, 32, 24)   0           batch_normalization_542[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_543 (Conv2D)             (None, 32, 32, 12)   2592        activation_542[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_185 (Dropout)           (None, 32, 32, 12)   0           conv2d_543[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 32, 32, 24)   0           conv2d_540[0][0]                 \n",
            "                                                                 dropout_185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_543 (BatchN (None, 32, 32, 24)   96          concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_543 (Activation)     (None, 32, 32, 24)   0           batch_normalization_543[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_544 (Conv2D)             (None, 32, 32, 48)   1152        activation_543[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_544 (BatchN (None, 32, 32, 48)   192         conv2d_544[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_544 (Activation)     (None, 32, 32, 48)   0           batch_normalization_544[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_545 (Conv2D)             (None, 32, 32, 24)   1152        activation_544[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_545 (BatchN (None, 32, 32, 24)   96          conv2d_545[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_545 (Activation)     (None, 32, 32, 24)   0           batch_normalization_545[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_546 (Conv2D)             (None, 32, 32, 12)   2592        activation_545[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_186 (Dropout)           (None, 32, 32, 12)   0           conv2d_546[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 32, 32, 36)   0           concatenate_177[0][0]            \n",
            "                                                                 dropout_186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_546 (BatchN (None, 32, 32, 36)   144         concatenate_178[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_546 (Activation)     (None, 32, 32, 36)   0           batch_normalization_546[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_547 (Conv2D)             (None, 32, 32, 48)   1728        activation_546[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_547 (BatchN (None, 32, 32, 48)   192         conv2d_547[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_547 (Activation)     (None, 32, 32, 48)   0           batch_normalization_547[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_548 (Conv2D)             (None, 32, 32, 24)   1152        activation_547[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_548 (BatchN (None, 32, 32, 24)   96          conv2d_548[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_548 (Activation)     (None, 32, 32, 24)   0           batch_normalization_548[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_549 (Conv2D)             (None, 32, 32, 12)   2592        activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_187 (Dropout)           (None, 32, 32, 12)   0           conv2d_549[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 32, 32, 48)   0           concatenate_178[0][0]            \n",
            "                                                                 dropout_187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_549 (BatchN (None, 32, 32, 48)   192         concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_549 (Activation)     (None, 32, 32, 48)   0           batch_normalization_549[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_550 (Conv2D)             (None, 32, 32, 48)   2304        activation_549[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_550 (BatchN (None, 32, 32, 48)   192         conv2d_550[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_550 (Activation)     (None, 32, 32, 48)   0           batch_normalization_550[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_551 (Conv2D)             (None, 32, 32, 24)   1152        activation_550[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_551 (BatchN (None, 32, 32, 24)   96          conv2d_551[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_551 (Activation)     (None, 32, 32, 24)   0           batch_normalization_551[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_552 (Conv2D)             (None, 32, 32, 12)   2592        activation_551[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_188 (Dropout)           (None, 32, 32, 12)   0           conv2d_552[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_180 (Concatenate)   (None, 32, 32, 60)   0           concatenate_179[0][0]            \n",
            "                                                                 dropout_188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, 32, 32, 60)   240         concatenate_180[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_552 (Activation)     (None, 32, 32, 60)   0           batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_553 (Conv2D)             (None, 32, 32, 48)   2880        activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, 32, 32, 48)   192         conv2d_553[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_553 (Activation)     (None, 32, 32, 48)   0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_554 (Conv2D)             (None, 32, 32, 24)   1152        activation_553[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, 32, 32, 24)   96          conv2d_554[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_554 (Activation)     (None, 32, 32, 24)   0           batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_555 (Conv2D)             (None, 32, 32, 12)   2592        activation_554[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_189 (Dropout)           (None, 32, 32, 12)   0           conv2d_555[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_181 (Concatenate)   (None, 32, 32, 72)   0           concatenate_180[0][0]            \n",
            "                                                                 dropout_189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, 32, 32, 72)   288         concatenate_181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_555 (Activation)     (None, 32, 32, 72)   0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_556 (Conv2D)             (None, 32, 32, 48)   3456        activation_555[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, 32, 32, 48)   192         conv2d_556[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_556 (Activation)     (None, 32, 32, 48)   0           batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_557 (Conv2D)             (None, 32, 32, 24)   1152        activation_556[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, 32, 32, 24)   96          conv2d_557[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_557 (Activation)     (None, 32, 32, 24)   0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_558 (Conv2D)             (None, 32, 32, 12)   2592        activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_190 (Dropout)           (None, 32, 32, 12)   0           conv2d_558[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_182 (Concatenate)   (None, 32, 32, 84)   0           concatenate_181[0][0]            \n",
            "                                                                 dropout_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, 32, 32, 84)   336         concatenate_182[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_558 (Activation)     (None, 32, 32, 84)   0           batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_559 (Conv2D)             (None, 32, 32, 48)   4032        activation_558[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, 32, 32, 48)   192         conv2d_559[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_559 (Activation)     (None, 32, 32, 48)   0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_560 (Conv2D)             (None, 32, 32, 24)   1152        activation_559[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, 32, 32, 24)   96          conv2d_560[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_560 (Activation)     (None, 32, 32, 24)   0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_561 (Conv2D)             (None, 32, 32, 12)   2592        activation_560[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_191 (Dropout)           (None, 32, 32, 12)   0           conv2d_561[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_183 (Concatenate)   (None, 32, 32, 96)   0           concatenate_182[0][0]            \n",
            "                                                                 dropout_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, 32, 32, 96)   384         concatenate_183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_561 (Activation)     (None, 32, 32, 96)   0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_562 (Conv2D)             (None, 32, 32, 48)   4608        activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_562 (BatchN (None, 32, 32, 48)   192         conv2d_562[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_562 (Activation)     (None, 32, 32, 48)   0           batch_normalization_562[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_563 (Conv2D)             (None, 32, 32, 24)   1152        activation_562[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_563 (BatchN (None, 32, 32, 24)   96          conv2d_563[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_563 (Activation)     (None, 32, 32, 24)   0           batch_normalization_563[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_564 (Conv2D)             (None, 32, 32, 12)   2592        activation_563[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_192 (Dropout)           (None, 32, 32, 12)   0           conv2d_564[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_184 (Concatenate)   (None, 32, 32, 108)  0           concatenate_183[0][0]            \n",
            "                                                                 dropout_192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_564 (BatchN (None, 32, 32, 108)  432         concatenate_184[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_564 (Activation)     (None, 32, 32, 108)  0           batch_normalization_564[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_565 (Conv2D)             (None, 32, 32, 48)   5184        activation_564[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_565 (BatchN (None, 32, 32, 48)   192         conv2d_565[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_565 (Activation)     (None, 32, 32, 48)   0           batch_normalization_565[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_566 (Conv2D)             (None, 32, 32, 24)   1152        activation_565[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_566 (BatchN (None, 32, 32, 24)   96          conv2d_566[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_566 (Activation)     (None, 32, 32, 24)   0           batch_normalization_566[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_567 (Conv2D)             (None, 32, 32, 12)   2592        activation_566[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_193 (Dropout)           (None, 32, 32, 12)   0           conv2d_567[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_185 (Concatenate)   (None, 32, 32, 120)  0           concatenate_184[0][0]            \n",
            "                                                                 dropout_193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_567 (BatchN (None, 32, 32, 120)  480         concatenate_185[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_567 (Activation)     (None, 32, 32, 120)  0           batch_normalization_567[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_568 (Conv2D)             (None, 32, 32, 48)   5760        activation_567[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_568 (BatchN (None, 32, 32, 48)   192         conv2d_568[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_568 (Activation)     (None, 32, 32, 48)   0           batch_normalization_568[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_569 (Conv2D)             (None, 32, 32, 24)   1152        activation_568[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_569 (BatchN (None, 32, 32, 24)   96          conv2d_569[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_569 (Activation)     (None, 32, 32, 24)   0           batch_normalization_569[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_570 (Conv2D)             (None, 32, 32, 12)   2592        activation_569[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_194 (Dropout)           (None, 32, 32, 12)   0           conv2d_570[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_186 (Concatenate)   (None, 32, 32, 132)  0           concatenate_185[0][0]            \n",
            "                                                                 dropout_194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_570 (BatchN (None, 32, 32, 132)  528         concatenate_186[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_570 (Activation)     (None, 32, 32, 132)  0           batch_normalization_570[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_571 (Conv2D)             (None, 32, 32, 48)   6336        activation_570[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_571 (BatchN (None, 32, 32, 48)   192         conv2d_571[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_571 (Activation)     (None, 32, 32, 48)   0           batch_normalization_571[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_572 (Conv2D)             (None, 32, 32, 24)   1152        activation_571[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_572 (BatchN (None, 32, 32, 24)   96          conv2d_572[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_572 (Activation)     (None, 32, 32, 24)   0           batch_normalization_572[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_573 (Conv2D)             (None, 32, 32, 12)   2592        activation_572[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_195 (Dropout)           (None, 32, 32, 12)   0           conv2d_573[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_187 (Concatenate)   (None, 32, 32, 144)  0           concatenate_186[0][0]            \n",
            "                                                                 dropout_195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_573 (BatchN (None, 32, 32, 144)  576         concatenate_187[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_573 (Activation)     (None, 32, 32, 144)  0           batch_normalization_573[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_574 (Conv2D)             (None, 32, 32, 48)   6912        activation_573[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_574 (BatchN (None, 32, 32, 48)   192         conv2d_574[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_574 (Activation)     (None, 32, 32, 48)   0           batch_normalization_574[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_575 (Conv2D)             (None, 32, 32, 24)   1152        activation_574[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_575 (BatchN (None, 32, 32, 24)   96          conv2d_575[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_575 (Activation)     (None, 32, 32, 24)   0           batch_normalization_575[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_576 (Conv2D)             (None, 32, 32, 12)   2592        activation_575[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_196 (Dropout)           (None, 32, 32, 12)   0           conv2d_576[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_188 (Concatenate)   (None, 32, 32, 156)  0           concatenate_187[0][0]            \n",
            "                                                                 dropout_196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_576 (BatchN (None, 32, 32, 156)  624         concatenate_188[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_576 (Activation)     (None, 32, 32, 156)  0           batch_normalization_576[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_577 (Conv2D)             (None, 32, 32, 48)   7488        activation_576[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_577 (BatchN (None, 32, 32, 48)   192         conv2d_577[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_577 (Activation)     (None, 32, 32, 48)   0           batch_normalization_577[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_578 (Conv2D)             (None, 32, 32, 24)   1152        activation_577[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_578 (BatchN (None, 32, 32, 24)   96          conv2d_578[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_578 (Activation)     (None, 32, 32, 24)   0           batch_normalization_578[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_579 (Conv2D)             (None, 32, 32, 12)   2592        activation_578[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_197 (Dropout)           (None, 32, 32, 12)   0           conv2d_579[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_189 (Concatenate)   (None, 32, 32, 168)  0           concatenate_188[0][0]            \n",
            "                                                                 dropout_197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_579 (BatchN (None, 32, 32, 168)  672         concatenate_189[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_579 (Activation)     (None, 32, 32, 168)  0           batch_normalization_579[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_580 (Conv2D)             (None, 32, 32, 48)   8064        activation_579[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_580 (BatchN (None, 32, 32, 48)   192         conv2d_580[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_580 (Activation)     (None, 32, 32, 48)   0           batch_normalization_580[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_581 (Conv2D)             (None, 32, 32, 24)   1152        activation_580[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_581 (BatchN (None, 32, 32, 24)   96          conv2d_581[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_581 (Activation)     (None, 32, 32, 24)   0           batch_normalization_581[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_582 (Conv2D)             (None, 32, 32, 12)   2592        activation_581[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_198 (Dropout)           (None, 32, 32, 12)   0           conv2d_582[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_190 (Concatenate)   (None, 32, 32, 180)  0           concatenate_189[0][0]            \n",
            "                                                                 dropout_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_582 (BatchN (None, 32, 32, 180)  720         concatenate_190[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_582 (Activation)     (None, 32, 32, 180)  0           batch_normalization_582[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_583 (Conv2D)             (None, 32, 32, 48)   8640        activation_582[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_583 (BatchN (None, 32, 32, 48)   192         conv2d_583[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_583 (Activation)     (None, 32, 32, 48)   0           batch_normalization_583[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_584 (Conv2D)             (None, 32, 32, 24)   1152        activation_583[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_584 (BatchN (None, 32, 32, 24)   96          conv2d_584[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_584 (Activation)     (None, 32, 32, 24)   0           batch_normalization_584[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_585 (Conv2D)             (None, 32, 32, 12)   2592        activation_584[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_199 (Dropout)           (None, 32, 32, 12)   0           conv2d_585[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_191 (Concatenate)   (None, 32, 32, 192)  0           concatenate_190[0][0]            \n",
            "                                                                 dropout_199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_585 (BatchN (None, 32, 32, 192)  768         concatenate_191[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_585 (Activation)     (None, 32, 32, 192)  0           batch_normalization_585[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_586 (Conv2D)             (None, 32, 32, 48)   9216        activation_585[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_586 (BatchN (None, 32, 32, 48)   192         conv2d_586[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_586 (Activation)     (None, 32, 32, 48)   0           batch_normalization_586[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_587 (Conv2D)             (None, 32, 32, 24)   1152        activation_586[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_587 (BatchN (None, 32, 32, 24)   96          conv2d_587[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_587 (Activation)     (None, 32, 32, 24)   0           batch_normalization_587[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_588 (Conv2D)             (None, 32, 32, 12)   2592        activation_587[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_200 (Dropout)           (None, 32, 32, 12)   0           conv2d_588[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_192 (Concatenate)   (None, 32, 32, 204)  0           concatenate_191[0][0]            \n",
            "                                                                 dropout_200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_588 (BatchN (None, 32, 32, 204)  816         concatenate_192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_588 (Activation)     (None, 32, 32, 204)  0           batch_normalization_588[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_589 (Conv2D)             (None, 32, 32, 12)   2448        activation_588[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_201 (Dropout)           (None, 32, 32, 12)   0           conv2d_589[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 12)   0           dropout_201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_589 (BatchN (None, 16, 16, 12)   48          average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_589 (Activation)     (None, 16, 16, 12)   0           batch_normalization_589[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_590 (Conv2D)             (None, 16, 16, 48)   576         activation_589[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_590 (BatchN (None, 16, 16, 48)   192         conv2d_590[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_590 (Activation)     (None, 16, 16, 48)   0           batch_normalization_590[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_591 (Conv2D)             (None, 16, 16, 24)   1152        activation_590[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_591 (BatchN (None, 16, 16, 24)   96          conv2d_591[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_591 (Activation)     (None, 16, 16, 24)   0           batch_normalization_591[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_592 (Conv2D)             (None, 16, 16, 12)   2592        activation_591[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_202 (Dropout)           (None, 16, 16, 12)   0           conv2d_592[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_193 (Concatenate)   (None, 16, 16, 24)   0           average_pooling2d_9[0][0]        \n",
            "                                                                 dropout_202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_592 (BatchN (None, 16, 16, 24)   96          concatenate_193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_592 (Activation)     (None, 16, 16, 24)   0           batch_normalization_592[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_593 (Conv2D)             (None, 16, 16, 48)   1152        activation_592[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_593 (BatchN (None, 16, 16, 48)   192         conv2d_593[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_593 (Activation)     (None, 16, 16, 48)   0           batch_normalization_593[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_594 (Conv2D)             (None, 16, 16, 24)   1152        activation_593[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_594 (BatchN (None, 16, 16, 24)   96          conv2d_594[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_594 (Activation)     (None, 16, 16, 24)   0           batch_normalization_594[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_595 (Conv2D)             (None, 16, 16, 12)   2592        activation_594[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 16, 16, 12)   0           conv2d_595[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_194 (Concatenate)   (None, 16, 16, 36)   0           concatenate_193[0][0]            \n",
            "                                                                 dropout_203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_595 (BatchN (None, 16, 16, 36)   144         concatenate_194[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_595 (Activation)     (None, 16, 16, 36)   0           batch_normalization_595[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_596 (Conv2D)             (None, 16, 16, 48)   1728        activation_595[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_596 (BatchN (None, 16, 16, 48)   192         conv2d_596[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_596 (Activation)     (None, 16, 16, 48)   0           batch_normalization_596[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_597 (Conv2D)             (None, 16, 16, 24)   1152        activation_596[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_597 (BatchN (None, 16, 16, 24)   96          conv2d_597[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_597 (Activation)     (None, 16, 16, 24)   0           batch_normalization_597[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_598 (Conv2D)             (None, 16, 16, 12)   2592        activation_597[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 16, 16, 12)   0           conv2d_598[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_195 (Concatenate)   (None, 16, 16, 48)   0           concatenate_194[0][0]            \n",
            "                                                                 dropout_204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_598 (BatchN (None, 16, 16, 48)   192         concatenate_195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_598 (Activation)     (None, 16, 16, 48)   0           batch_normalization_598[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_599 (Conv2D)             (None, 16, 16, 48)   2304        activation_598[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_599 (BatchN (None, 16, 16, 48)   192         conv2d_599[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_599 (Activation)     (None, 16, 16, 48)   0           batch_normalization_599[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_600 (Conv2D)             (None, 16, 16, 24)   1152        activation_599[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_600 (BatchN (None, 16, 16, 24)   96          conv2d_600[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_600 (Activation)     (None, 16, 16, 24)   0           batch_normalization_600[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_601 (Conv2D)             (None, 16, 16, 12)   2592        activation_600[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 16, 16, 12)   0           conv2d_601[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_196 (Concatenate)   (None, 16, 16, 60)   0           concatenate_195[0][0]            \n",
            "                                                                 dropout_205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_601 (BatchN (None, 16, 16, 60)   240         concatenate_196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_601 (Activation)     (None, 16, 16, 60)   0           batch_normalization_601[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_602 (Conv2D)             (None, 16, 16, 48)   2880        activation_601[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_602 (BatchN (None, 16, 16, 48)   192         conv2d_602[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_602 (Activation)     (None, 16, 16, 48)   0           batch_normalization_602[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_603 (Conv2D)             (None, 16, 16, 24)   1152        activation_602[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_603 (BatchN (None, 16, 16, 24)   96          conv2d_603[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_603 (Activation)     (None, 16, 16, 24)   0           batch_normalization_603[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_604 (Conv2D)             (None, 16, 16, 12)   2592        activation_603[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 16, 16, 12)   0           conv2d_604[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_197 (Concatenate)   (None, 16, 16, 72)   0           concatenate_196[0][0]            \n",
            "                                                                 dropout_206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_604 (BatchN (None, 16, 16, 72)   288         concatenate_197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_604 (Activation)     (None, 16, 16, 72)   0           batch_normalization_604[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_605 (Conv2D)             (None, 16, 16, 48)   3456        activation_604[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_605 (BatchN (None, 16, 16, 48)   192         conv2d_605[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_605 (Activation)     (None, 16, 16, 48)   0           batch_normalization_605[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_606 (Conv2D)             (None, 16, 16, 24)   1152        activation_605[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_606 (BatchN (None, 16, 16, 24)   96          conv2d_606[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_606 (Activation)     (None, 16, 16, 24)   0           batch_normalization_606[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_607 (Conv2D)             (None, 16, 16, 12)   2592        activation_606[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 16, 16, 12)   0           conv2d_607[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_198 (Concatenate)   (None, 16, 16, 84)   0           concatenate_197[0][0]            \n",
            "                                                                 dropout_207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_607 (BatchN (None, 16, 16, 84)   336         concatenate_198[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_607 (Activation)     (None, 16, 16, 84)   0           batch_normalization_607[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_608 (Conv2D)             (None, 16, 16, 48)   4032        activation_607[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_608 (BatchN (None, 16, 16, 48)   192         conv2d_608[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_608 (Activation)     (None, 16, 16, 48)   0           batch_normalization_608[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_609 (Conv2D)             (None, 16, 16, 24)   1152        activation_608[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_609 (BatchN (None, 16, 16, 24)   96          conv2d_609[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_609 (Activation)     (None, 16, 16, 24)   0           batch_normalization_609[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_610 (Conv2D)             (None, 16, 16, 12)   2592        activation_609[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 16, 16, 12)   0           conv2d_610[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_199 (Concatenate)   (None, 16, 16, 96)   0           concatenate_198[0][0]            \n",
            "                                                                 dropout_208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_610 (BatchN (None, 16, 16, 96)   384         concatenate_199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_610 (Activation)     (None, 16, 16, 96)   0           batch_normalization_610[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_611 (Conv2D)             (None, 16, 16, 48)   4608        activation_610[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_611 (BatchN (None, 16, 16, 48)   192         conv2d_611[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_611 (Activation)     (None, 16, 16, 48)   0           batch_normalization_611[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_612 (Conv2D)             (None, 16, 16, 24)   1152        activation_611[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_612 (BatchN (None, 16, 16, 24)   96          conv2d_612[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_612 (Activation)     (None, 16, 16, 24)   0           batch_normalization_612[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_613 (Conv2D)             (None, 16, 16, 12)   2592        activation_612[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 16, 16, 12)   0           conv2d_613[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_200 (Concatenate)   (None, 16, 16, 108)  0           concatenate_199[0][0]            \n",
            "                                                                 dropout_209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_613 (BatchN (None, 16, 16, 108)  432         concatenate_200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_613 (Activation)     (None, 16, 16, 108)  0           batch_normalization_613[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_614 (Conv2D)             (None, 16, 16, 48)   5184        activation_613[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_614 (BatchN (None, 16, 16, 48)   192         conv2d_614[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_614 (Activation)     (None, 16, 16, 48)   0           batch_normalization_614[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_615 (Conv2D)             (None, 16, 16, 24)   1152        activation_614[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_615 (BatchN (None, 16, 16, 24)   96          conv2d_615[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_615 (Activation)     (None, 16, 16, 24)   0           batch_normalization_615[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_616 (Conv2D)             (None, 16, 16, 12)   2592        activation_615[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_210 (Dropout)           (None, 16, 16, 12)   0           conv2d_616[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_201 (Concatenate)   (None, 16, 16, 120)  0           concatenate_200[0][0]            \n",
            "                                                                 dropout_210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_616 (BatchN (None, 16, 16, 120)  480         concatenate_201[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_616 (Activation)     (None, 16, 16, 120)  0           batch_normalization_616[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_617 (Conv2D)             (None, 16, 16, 48)   5760        activation_616[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_617 (BatchN (None, 16, 16, 48)   192         conv2d_617[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_617 (Activation)     (None, 16, 16, 48)   0           batch_normalization_617[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_618 (Conv2D)             (None, 16, 16, 24)   1152        activation_617[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_618 (BatchN (None, 16, 16, 24)   96          conv2d_618[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_618 (Activation)     (None, 16, 16, 24)   0           batch_normalization_618[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_619 (Conv2D)             (None, 16, 16, 12)   2592        activation_618[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 16, 16, 12)   0           conv2d_619[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_202 (Concatenate)   (None, 16, 16, 132)  0           concatenate_201[0][0]            \n",
            "                                                                 dropout_211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_619 (BatchN (None, 16, 16, 132)  528         concatenate_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_619 (Activation)     (None, 16, 16, 132)  0           batch_normalization_619[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_620 (Conv2D)             (None, 16, 16, 48)   6336        activation_619[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_620 (BatchN (None, 16, 16, 48)   192         conv2d_620[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_620 (Activation)     (None, 16, 16, 48)   0           batch_normalization_620[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_621 (Conv2D)             (None, 16, 16, 24)   1152        activation_620[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_621 (BatchN (None, 16, 16, 24)   96          conv2d_621[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_621 (Activation)     (None, 16, 16, 24)   0           batch_normalization_621[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_622 (Conv2D)             (None, 16, 16, 12)   2592        activation_621[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 16, 16, 12)   0           conv2d_622[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_203 (Concatenate)   (None, 16, 16, 144)  0           concatenate_202[0][0]            \n",
            "                                                                 dropout_212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_622 (BatchN (None, 16, 16, 144)  576         concatenate_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_622 (Activation)     (None, 16, 16, 144)  0           batch_normalization_622[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_623 (Conv2D)             (None, 16, 16, 48)   6912        activation_622[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_623 (BatchN (None, 16, 16, 48)   192         conv2d_623[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_623 (Activation)     (None, 16, 16, 48)   0           batch_normalization_623[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_624 (Conv2D)             (None, 16, 16, 24)   1152        activation_623[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_624 (BatchN (None, 16, 16, 24)   96          conv2d_624[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_624 (Activation)     (None, 16, 16, 24)   0           batch_normalization_624[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_625 (Conv2D)             (None, 16, 16, 12)   2592        activation_624[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 16, 16, 12)   0           conv2d_625[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_204 (Concatenate)   (None, 16, 16, 156)  0           concatenate_203[0][0]            \n",
            "                                                                 dropout_213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_625 (BatchN (None, 16, 16, 156)  624         concatenate_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_625 (Activation)     (None, 16, 16, 156)  0           batch_normalization_625[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_626 (Conv2D)             (None, 16, 16, 48)   7488        activation_625[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_626 (BatchN (None, 16, 16, 48)   192         conv2d_626[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_626 (Activation)     (None, 16, 16, 48)   0           batch_normalization_626[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_627 (Conv2D)             (None, 16, 16, 24)   1152        activation_626[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_627 (BatchN (None, 16, 16, 24)   96          conv2d_627[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_627 (Activation)     (None, 16, 16, 24)   0           batch_normalization_627[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_628 (Conv2D)             (None, 16, 16, 12)   2592        activation_627[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 16, 16, 12)   0           conv2d_628[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_205 (Concatenate)   (None, 16, 16, 168)  0           concatenate_204[0][0]            \n",
            "                                                                 dropout_214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_628 (BatchN (None, 16, 16, 168)  672         concatenate_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_628 (Activation)     (None, 16, 16, 168)  0           batch_normalization_628[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_629 (Conv2D)             (None, 16, 16, 48)   8064        activation_628[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_629 (BatchN (None, 16, 16, 48)   192         conv2d_629[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_629 (Activation)     (None, 16, 16, 48)   0           batch_normalization_629[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_630 (Conv2D)             (None, 16, 16, 24)   1152        activation_629[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_630 (BatchN (None, 16, 16, 24)   96          conv2d_630[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_630 (Activation)     (None, 16, 16, 24)   0           batch_normalization_630[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_631 (Conv2D)             (None, 16, 16, 12)   2592        activation_630[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 16, 16, 12)   0           conv2d_631[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_206 (Concatenate)   (None, 16, 16, 180)  0           concatenate_205[0][0]            \n",
            "                                                                 dropout_215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_631 (BatchN (None, 16, 16, 180)  720         concatenate_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_631 (Activation)     (None, 16, 16, 180)  0           batch_normalization_631[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_632 (Conv2D)             (None, 16, 16, 48)   8640        activation_631[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_632 (BatchN (None, 16, 16, 48)   192         conv2d_632[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_632 (Activation)     (None, 16, 16, 48)   0           batch_normalization_632[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_633 (Conv2D)             (None, 16, 16, 24)   1152        activation_632[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_633 (BatchN (None, 16, 16, 24)   96          conv2d_633[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_633 (Activation)     (None, 16, 16, 24)   0           batch_normalization_633[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_634 (Conv2D)             (None, 16, 16, 12)   2592        activation_633[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 16, 16, 12)   0           conv2d_634[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_207 (Concatenate)   (None, 16, 16, 192)  0           concatenate_206[0][0]            \n",
            "                                                                 dropout_216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_634 (BatchN (None, 16, 16, 192)  768         concatenate_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_634 (Activation)     (None, 16, 16, 192)  0           batch_normalization_634[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_635 (Conv2D)             (None, 16, 16, 48)   9216        activation_634[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_635 (BatchN (None, 16, 16, 48)   192         conv2d_635[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_635 (Activation)     (None, 16, 16, 48)   0           batch_normalization_635[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_636 (Conv2D)             (None, 16, 16, 24)   1152        activation_635[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_636 (BatchN (None, 16, 16, 24)   96          conv2d_636[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_636 (Activation)     (None, 16, 16, 24)   0           batch_normalization_636[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_637 (Conv2D)             (None, 16, 16, 12)   2592        activation_636[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 16, 16, 12)   0           conv2d_637[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_208 (Concatenate)   (None, 16, 16, 204)  0           concatenate_207[0][0]            \n",
            "                                                                 dropout_217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_637 (BatchN (None, 16, 16, 204)  816         concatenate_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_637 (Activation)     (None, 16, 16, 204)  0           batch_normalization_637[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_638 (Conv2D)             (None, 16, 16, 12)   2448        activation_637[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 16, 16, 12)   0           conv2d_638[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 8, 8, 12)     0           dropout_218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_638 (BatchN (None, 8, 8, 12)     48          average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_638 (Activation)     (None, 8, 8, 12)     0           batch_normalization_638[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_639 (Conv2D)             (None, 8, 8, 48)     576         activation_638[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_639 (BatchN (None, 8, 8, 48)     192         conv2d_639[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_639 (Activation)     (None, 8, 8, 48)     0           batch_normalization_639[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_640 (Conv2D)             (None, 8, 8, 24)     1152        activation_639[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_640 (BatchN (None, 8, 8, 24)     96          conv2d_640[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_640 (Activation)     (None, 8, 8, 24)     0           batch_normalization_640[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_641 (Conv2D)             (None, 8, 8, 12)     2592        activation_640[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 8, 8, 12)     0           conv2d_641[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_209 (Concatenate)   (None, 8, 8, 24)     0           average_pooling2d_10[0][0]       \n",
            "                                                                 dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_641 (BatchN (None, 8, 8, 24)     96          concatenate_209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_641 (Activation)     (None, 8, 8, 24)     0           batch_normalization_641[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_642 (Conv2D)             (None, 8, 8, 48)     1152        activation_641[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_642 (BatchN (None, 8, 8, 48)     192         conv2d_642[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_642 (Activation)     (None, 8, 8, 48)     0           batch_normalization_642[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_643 (Conv2D)             (None, 8, 8, 24)     1152        activation_642[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_643 (BatchN (None, 8, 8, 24)     96          conv2d_643[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_643 (Activation)     (None, 8, 8, 24)     0           batch_normalization_643[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_644 (Conv2D)             (None, 8, 8, 12)     2592        activation_643[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 8, 8, 12)     0           conv2d_644[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_210 (Concatenate)   (None, 8, 8, 36)     0           concatenate_209[0][0]            \n",
            "                                                                 dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_644 (BatchN (None, 8, 8, 36)     144         concatenate_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_644 (Activation)     (None, 8, 8, 36)     0           batch_normalization_644[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_645 (Conv2D)             (None, 8, 8, 48)     1728        activation_644[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_645 (BatchN (None, 8, 8, 48)     192         conv2d_645[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_645 (Activation)     (None, 8, 8, 48)     0           batch_normalization_645[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_646 (Conv2D)             (None, 8, 8, 24)     1152        activation_645[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_646 (BatchN (None, 8, 8, 24)     96          conv2d_646[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_646 (Activation)     (None, 8, 8, 24)     0           batch_normalization_646[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_647 (Conv2D)             (None, 8, 8, 12)     2592        activation_646[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 8, 8, 12)     0           conv2d_647[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_211 (Concatenate)   (None, 8, 8, 48)     0           concatenate_210[0][0]            \n",
            "                                                                 dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_647 (BatchN (None, 8, 8, 48)     192         concatenate_211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_647 (Activation)     (None, 8, 8, 48)     0           batch_normalization_647[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_648 (Conv2D)             (None, 8, 8, 48)     2304        activation_647[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_648 (BatchN (None, 8, 8, 48)     192         conv2d_648[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_648 (Activation)     (None, 8, 8, 48)     0           batch_normalization_648[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_649 (Conv2D)             (None, 8, 8, 24)     1152        activation_648[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_649 (BatchN (None, 8, 8, 24)     96          conv2d_649[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_649 (Activation)     (None, 8, 8, 24)     0           batch_normalization_649[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_650 (Conv2D)             (None, 8, 8, 12)     2592        activation_649[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 8, 8, 12)     0           conv2d_650[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_212 (Concatenate)   (None, 8, 8, 60)     0           concatenate_211[0][0]            \n",
            "                                                                 dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_650 (BatchN (None, 8, 8, 60)     240         concatenate_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_650 (Activation)     (None, 8, 8, 60)     0           batch_normalization_650[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_651 (Conv2D)             (None, 8, 8, 48)     2880        activation_650[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_651 (BatchN (None, 8, 8, 48)     192         conv2d_651[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_651 (Activation)     (None, 8, 8, 48)     0           batch_normalization_651[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_652 (Conv2D)             (None, 8, 8, 24)     1152        activation_651[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_652 (BatchN (None, 8, 8, 24)     96          conv2d_652[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_652 (Activation)     (None, 8, 8, 24)     0           batch_normalization_652[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_653 (Conv2D)             (None, 8, 8, 12)     2592        activation_652[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 8, 8, 12)     0           conv2d_653[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_213 (Concatenate)   (None, 8, 8, 72)     0           concatenate_212[0][0]            \n",
            "                                                                 dropout_223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_653 (BatchN (None, 8, 8, 72)     288         concatenate_213[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_653 (Activation)     (None, 8, 8, 72)     0           batch_normalization_653[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_654 (Conv2D)             (None, 8, 8, 48)     3456        activation_653[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_654 (BatchN (None, 8, 8, 48)     192         conv2d_654[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_654 (Activation)     (None, 8, 8, 48)     0           batch_normalization_654[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_655 (Conv2D)             (None, 8, 8, 24)     1152        activation_654[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_655 (BatchN (None, 8, 8, 24)     96          conv2d_655[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_655 (Activation)     (None, 8, 8, 24)     0           batch_normalization_655[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_656 (Conv2D)             (None, 8, 8, 12)     2592        activation_655[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_224 (Dropout)           (None, 8, 8, 12)     0           conv2d_656[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_214 (Concatenate)   (None, 8, 8, 84)     0           concatenate_213[0][0]            \n",
            "                                                                 dropout_224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_656 (BatchN (None, 8, 8, 84)     336         concatenate_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_656 (Activation)     (None, 8, 8, 84)     0           batch_normalization_656[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_657 (Conv2D)             (None, 8, 8, 48)     4032        activation_656[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_657 (BatchN (None, 8, 8, 48)     192         conv2d_657[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_657 (Activation)     (None, 8, 8, 48)     0           batch_normalization_657[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_658 (Conv2D)             (None, 8, 8, 24)     1152        activation_657[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_658 (BatchN (None, 8, 8, 24)     96          conv2d_658[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_658 (Activation)     (None, 8, 8, 24)     0           batch_normalization_658[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_659 (Conv2D)             (None, 8, 8, 12)     2592        activation_658[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_225 (Dropout)           (None, 8, 8, 12)     0           conv2d_659[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_215 (Concatenate)   (None, 8, 8, 96)     0           concatenate_214[0][0]            \n",
            "                                                                 dropout_225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_659 (BatchN (None, 8, 8, 96)     384         concatenate_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_659 (Activation)     (None, 8, 8, 96)     0           batch_normalization_659[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_660 (Conv2D)             (None, 8, 8, 48)     4608        activation_659[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_660 (BatchN (None, 8, 8, 48)     192         conv2d_660[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_660 (Activation)     (None, 8, 8, 48)     0           batch_normalization_660[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_661 (Conv2D)             (None, 8, 8, 24)     1152        activation_660[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_661 (BatchN (None, 8, 8, 24)     96          conv2d_661[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_661 (Activation)     (None, 8, 8, 24)     0           batch_normalization_661[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_662 (Conv2D)             (None, 8, 8, 12)     2592        activation_661[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_226 (Dropout)           (None, 8, 8, 12)     0           conv2d_662[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_216 (Concatenate)   (None, 8, 8, 108)    0           concatenate_215[0][0]            \n",
            "                                                                 dropout_226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_662 (BatchN (None, 8, 8, 108)    432         concatenate_216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_662 (Activation)     (None, 8, 8, 108)    0           batch_normalization_662[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_663 (Conv2D)             (None, 8, 8, 48)     5184        activation_662[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_663 (BatchN (None, 8, 8, 48)     192         conv2d_663[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_663 (Activation)     (None, 8, 8, 48)     0           batch_normalization_663[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_664 (Conv2D)             (None, 8, 8, 24)     1152        activation_663[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_664 (BatchN (None, 8, 8, 24)     96          conv2d_664[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_664 (Activation)     (None, 8, 8, 24)     0           batch_normalization_664[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_665 (Conv2D)             (None, 8, 8, 12)     2592        activation_664[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 8, 8, 12)     0           conv2d_665[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_217 (Concatenate)   (None, 8, 8, 120)    0           concatenate_216[0][0]            \n",
            "                                                                 dropout_227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_665 (BatchN (None, 8, 8, 120)    480         concatenate_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_665 (Activation)     (None, 8, 8, 120)    0           batch_normalization_665[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_666 (Conv2D)             (None, 8, 8, 48)     5760        activation_665[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_666 (BatchN (None, 8, 8, 48)     192         conv2d_666[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_666 (Activation)     (None, 8, 8, 48)     0           batch_normalization_666[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_667 (Conv2D)             (None, 8, 8, 24)     1152        activation_666[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_667 (BatchN (None, 8, 8, 24)     96          conv2d_667[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_667 (Activation)     (None, 8, 8, 24)     0           batch_normalization_667[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_668 (Conv2D)             (None, 8, 8, 12)     2592        activation_667[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_228 (Dropout)           (None, 8, 8, 12)     0           conv2d_668[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_218 (Concatenate)   (None, 8, 8, 132)    0           concatenate_217[0][0]            \n",
            "                                                                 dropout_228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_668 (BatchN (None, 8, 8, 132)    528         concatenate_218[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_668 (Activation)     (None, 8, 8, 132)    0           batch_normalization_668[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_669 (Conv2D)             (None, 8, 8, 48)     6336        activation_668[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_669 (BatchN (None, 8, 8, 48)     192         conv2d_669[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_669 (Activation)     (None, 8, 8, 48)     0           batch_normalization_669[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_670 (Conv2D)             (None, 8, 8, 24)     1152        activation_669[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_670 (BatchN (None, 8, 8, 24)     96          conv2d_670[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_670 (Activation)     (None, 8, 8, 24)     0           batch_normalization_670[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_671 (Conv2D)             (None, 8, 8, 12)     2592        activation_670[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_229 (Dropout)           (None, 8, 8, 12)     0           conv2d_671[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_219 (Concatenate)   (None, 8, 8, 144)    0           concatenate_218[0][0]            \n",
            "                                                                 dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_671 (BatchN (None, 8, 8, 144)    576         concatenate_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_671 (Activation)     (None, 8, 8, 144)    0           batch_normalization_671[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_672 (Conv2D)             (None, 8, 8, 48)     6912        activation_671[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_672 (BatchN (None, 8, 8, 48)     192         conv2d_672[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_672 (Activation)     (None, 8, 8, 48)     0           batch_normalization_672[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_673 (Conv2D)             (None, 8, 8, 24)     1152        activation_672[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_673 (BatchN (None, 8, 8, 24)     96          conv2d_673[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_673 (Activation)     (None, 8, 8, 24)     0           batch_normalization_673[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_674 (Conv2D)             (None, 8, 8, 12)     2592        activation_673[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_230 (Dropout)           (None, 8, 8, 12)     0           conv2d_674[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_220 (Concatenate)   (None, 8, 8, 156)    0           concatenate_219[0][0]            \n",
            "                                                                 dropout_230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_674 (BatchN (None, 8, 8, 156)    624         concatenate_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_674 (Activation)     (None, 8, 8, 156)    0           batch_normalization_674[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_675 (Conv2D)             (None, 8, 8, 48)     7488        activation_674[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_675 (BatchN (None, 8, 8, 48)     192         conv2d_675[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_675 (Activation)     (None, 8, 8, 48)     0           batch_normalization_675[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_676 (Conv2D)             (None, 8, 8, 24)     1152        activation_675[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_676 (BatchN (None, 8, 8, 24)     96          conv2d_676[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_676 (Activation)     (None, 8, 8, 24)     0           batch_normalization_676[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_677 (Conv2D)             (None, 8, 8, 12)     2592        activation_676[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_231 (Dropout)           (None, 8, 8, 12)     0           conv2d_677[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_221 (Concatenate)   (None, 8, 8, 168)    0           concatenate_220[0][0]            \n",
            "                                                                 dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_677 (BatchN (None, 8, 8, 168)    672         concatenate_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_677 (Activation)     (None, 8, 8, 168)    0           batch_normalization_677[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_678 (Conv2D)             (None, 8, 8, 48)     8064        activation_677[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_678 (BatchN (None, 8, 8, 48)     192         conv2d_678[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_678 (Activation)     (None, 8, 8, 48)     0           batch_normalization_678[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_679 (Conv2D)             (None, 8, 8, 24)     1152        activation_678[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_679 (BatchN (None, 8, 8, 24)     96          conv2d_679[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_679 (Activation)     (None, 8, 8, 24)     0           batch_normalization_679[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_680 (Conv2D)             (None, 8, 8, 12)     2592        activation_679[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_232 (Dropout)           (None, 8, 8, 12)     0           conv2d_680[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_222 (Concatenate)   (None, 8, 8, 180)    0           concatenate_221[0][0]            \n",
            "                                                                 dropout_232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_680 (BatchN (None, 8, 8, 180)    720         concatenate_222[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_680 (Activation)     (None, 8, 8, 180)    0           batch_normalization_680[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_681 (Conv2D)             (None, 8, 8, 48)     8640        activation_680[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_681 (BatchN (None, 8, 8, 48)     192         conv2d_681[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_681 (Activation)     (None, 8, 8, 48)     0           batch_normalization_681[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_682 (Conv2D)             (None, 8, 8, 24)     1152        activation_681[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_682 (BatchN (None, 8, 8, 24)     96          conv2d_682[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_682 (Activation)     (None, 8, 8, 24)     0           batch_normalization_682[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_683 (Conv2D)             (None, 8, 8, 12)     2592        activation_682[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_233 (Dropout)           (None, 8, 8, 12)     0           conv2d_683[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_223 (Concatenate)   (None, 8, 8, 192)    0           concatenate_222[0][0]            \n",
            "                                                                 dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_683 (BatchN (None, 8, 8, 192)    768         concatenate_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_683 (Activation)     (None, 8, 8, 192)    0           batch_normalization_683[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_684 (Conv2D)             (None, 8, 8, 48)     9216        activation_683[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_684 (BatchN (None, 8, 8, 48)     192         conv2d_684[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_684 (Activation)     (None, 8, 8, 48)     0           batch_normalization_684[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_685 (Conv2D)             (None, 8, 8, 24)     1152        activation_684[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_685 (BatchN (None, 8, 8, 24)     96          conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_685 (Activation)     (None, 8, 8, 24)     0           batch_normalization_685[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_686 (Conv2D)             (None, 8, 8, 12)     2592        activation_685[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_234 (Dropout)           (None, 8, 8, 12)     0           conv2d_686[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_224 (Concatenate)   (None, 8, 8, 204)    0           concatenate_223[0][0]            \n",
            "                                                                 dropout_234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_735 (BatchN (None, 8, 8, 204)    816         concatenate_224[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_735 (Activation)     (None, 8, 8, 204)    0           batch_normalization_735[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 204)          0           activation_735[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           2050        global_average_pooling2d_4[0][0] \n",
            "==================================================================================================\n",
            "Total params: 457,846\n",
            "Trainable params: 439,918\n",
            "Non-trainable params: 17,928\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "991f8e371577a1f2e8197827dab5aac2406ef1b1",
        "id": "kpe9EljYyLGq",
        "colab_type": "code",
        "outputId": "84bb6500-fcc3-40a4-880d-1aade70d055f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "print('====================HYPER PARAMETERS====================')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================HYPER PARAMETERS====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "7c17f4244c917e97e7cc1557ae60bce8dba7e47e",
        "id": "JVTAyE2OyLIW",
        "colab_type": "code",
        "outputId": "7527fbf1-aa09-46bb-9bc7-7ff15bdfbbd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "x_train, y_train, x_test, y_test = load_data(resize=False,append=False)#,train_augment=False\n",
        "hist=[]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before augmentation: (50000, 32, 32, 3) (50000, 10)\n",
            "After augmentation: (50000, 32, 32, 3) (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A89juSamtr--",
        "colab_type": "code",
        "outputId": "a22e4451-58cc-4a98-c6ee-461fafc6b77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1393
        }
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "batch_size=128\n",
        "modval=8\n",
        "max_lr=0.3\n",
        "\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.1, max_lr=0.2,step_size=8*(len(y_train)/batch_size))\n",
        "\n",
        "use_cosine_annealing=False\n",
        "lrs=LearningRateScheduler(cosine_anneal_schedule) if use_cosine_annealing else clr\n",
        "callbacks = [model_checkpointer,lrs]\n",
        "initial_epoch=epochs\n",
        "epochs=24\n",
        "epochs+=initial_epoch\n",
        "\n",
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=initial_epoch,epochs=epochs, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 25/48\n",
            "50000/50000 [==============================] - 323s 6ms/step - loss: 2.0217 - acc: 0.2341 - val_loss: 1.9416 - val_acc: 0.2877\n",
            "Epoch 26/48\n",
            "50000/50000 [==============================] - 300s 6ms/step - loss: 1.8842 - acc: 0.3007 - val_loss: 1.9554 - val_acc: 0.3198\n",
            "\n",
            "Epoch 00026: val_acc improved from -inf to 0.31980, saving model to /content/gdrive/My Drive/Colab Notebooks/weights/large_weights.26-0.32.h5\n",
            "Epoch 27/48\n",
            "50000/50000 [==============================] - 303s 6ms/step - loss: 1.8387 - acc: 0.3230 - val_loss: 1.8963 - val_acc: 0.3272\n",
            "Epoch 28/48\n",
            "50000/50000 [==============================] - 303s 6ms/step - loss: 1.8030 - acc: 0.3403 - val_loss: 1.8915 - val_acc: 0.3391\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.31980 to 0.33910, saving model to /content/gdrive/My Drive/Colab Notebooks/weights/large_weights.28-0.34.h5\n",
            "Epoch 29/48\n",
            "50000/50000 [==============================] - 303s 6ms/step - loss: 1.7739 - acc: 0.3520 - val_loss: 1.8054 - val_acc: 0.3656\n",
            "Epoch 30/48\n",
            "13696/50000 [=======>......................] - ETA: 3:28 - loss: 1.7520 - acc: 0.3612"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-53cb0a958ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_contrib/callbacks/cyclical_learning_rate.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_iterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclr_iterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         self.history.setdefault(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mset_value\u001b[0;34m(x, value)\u001b[0m\n\u001b[1;32m   2441\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2443\u001b[0;31m     \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "B_Ga-L2tOC6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "batch_size=100\n",
        "modval=8\n",
        "max_lr=0.3\n",
        "\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.01, max_lr=0.2,step_size=4*(len(y_train)/batch_size))\n",
        "\n",
        "use_cosine_annealing=False\n",
        "lrs=LearningRateScheduler(cosine_anneal_schedule) if use_cosine_annealing else clr\n",
        "callbacks = [model_checkpointer,lrs]\n",
        "initial_epoch=epochs\n",
        "epochs=8\n",
        "epochs+=initial_epoch\n",
        "\n",
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=initial_epoch,epochs=epochs, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ujuhZCSKIwrB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "batch_size=128\n",
        "modval=8\n",
        "max_lr=0.3\n",
        "\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.01, max_lr=0.1,step_size=8*(len(y_train)/batch_size))\n",
        "\n",
        "use_cosine_annealing=False\n",
        "lrs=LearningRateScheduler(cosine_anneal_schedule) if use_cosine_annealing else clr\n",
        "callbacks = [model_checkpointer,lrs]\n",
        "initial_epoch=epochs\n",
        "epochs=8\n",
        "epochs+=initial_epoch\n",
        "\n",
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=initial_epoch,epochs=epochs, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6N_5LhaUqfWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_train, y_train, x_test, y_test = load_data(resize=False,append=True)#,train_augment=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4HfaujzqmoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "batch_size=128\n",
        "modval=8\n",
        "max_lr=0.3\n",
        "\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.001, max_lr=0.1,step_size=8*(len(y_train)/batch_size))\n",
        "\n",
        "use_cosine_annealing=False\n",
        "lrs=LearningRateScheduler(cosine_anneal_schedule) if use_cosine_annealing else clr\n",
        "callbacks = [model_checkpointer,lrs]\n",
        "initial_epoch=epochs\n",
        "epochs=40\n",
        "epochs+=initial_epoch\n",
        "\n",
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=initial_epoch,epochs=epochs, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7be8a1352f65787da27dc9eeb8b9073890561062",
        "id": "YmAAYyWYyLJ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6151d97fb488aed1553bb9ae29fcb9e3e0bf1f08",
        "id": "kEa47QYDyLJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('====================END OF LARGER MODEL====================')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4UMePG4KrGA5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}