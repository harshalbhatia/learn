{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-4-custom_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "f67729355a01c19c62bfa2145d9594b1da821fc6",
        "id": "AbFZ1CPnyLEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d45ed4fe-45e1-4d75-8a7a-e8c8c59762a4"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q six numpy scipy matplotlib scikit-image opencv-python imageio\n",
        "!pip install -q keras imgaug\n",
        "!pip install tensorboardcolab\n",
        "!pip install -q git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: tensorboardcolab\n",
            "Successfully installed tensorboardcolab-0.0.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "jwLq5vZ1yLE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras_contrib.callbacks import CyclicLR, DeadReluDetector, SnapshotCallbackBuilder, SnapshotModelCheckpoint\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "363049cf0704e0aebfa7ea4994c6c291fd66cbac",
        "id": "uEbrjMRqyLFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# from keras.callbacks import LearningRateScheduler,ModelCheckpoint,EarlyStopping,LambdaCallback\n",
        "import os,sys,math\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22f446b53ec82f3244c33dd780ab24b896178cf9",
        "id": "HGIF2j6YyLFc",
        "colab_type": "code",
        "outputId": "3a5a12a8-d004-461b-a3ce-21fce63f521b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import google\n",
        "colab_dir='./'\n",
        "file_name='EIP_CIFAR_10'\n",
        "if hasattr(google,'colab'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    colab_dir='/content/gdrive/My Drive/Colab Notebooks/'\n",
        "model_file=colab_dir+file_name+'.h5'\n",
        "weights_dir=colab_dir+'weights/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://c0a0eaff.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "beylEPLZyLFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa9bb45cb7f0171c15c4b065ade989e82042b15a",
        "id": "VKufdLiEyLFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Augmentation and resizing\n",
        "#augment and then concat samples with original\n",
        "def augment(dataset,flip=0.5,blur=1.0):\n",
        "    ia.seed(1)\n",
        "#     seq = iaa.Sequential([iaa.Fliplr(flip),iaa.GaussianBlur(sigma=(0, blur)),iaa.Sometimes(iaa.Crop(percent=(0, 0.1))),\n",
        "#                          iaa.Sometimes(iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "#                                              translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "#                                              rotate=(-45, 45),shear=(-16, 16),order=[0, 1],cval=(0, 255),mode=ia.ALL))])\n",
        "    seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Crop(percent=(0, 0.1)),\n",
        "    iaa.Sometimes(0.5,\n",
        "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
        "    ),\n",
        "    iaa.ContrastNormalization((0.75, 1.5)),\n",
        "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        shear=(-8, 8))], random_order=True)    \n",
        "    return seq.augment_images(dataset)\n",
        "\n",
        "def augmenter(X,y,start=0,end=1,na=False):\n",
        "    ln=len(X)\n",
        "    print('Before augmentation:',X.shape,y.shape)\n",
        "    start=int(start*ln)\n",
        "    end=int(end*ln)\n",
        "    if na:\n",
        "      X=augment(X)\n",
        "    else:\n",
        "      new_X=augment(X)[start:end]\n",
        "      new_y=y[start:end]\n",
        "      X=np.concatenate((X,new_X))\n",
        "      y=np.concatenate((y,new_y))\n",
        "    print('After augmentation:',X.shape,y.shape)\n",
        "    return (X,y)\n",
        "\n",
        "#26x26 is almost half of 32x32. 22x22 maybe too small even though its exact half.\n",
        "def resize_imgs(imgs,shape=(26,26)):\n",
        "    seq = iaa.Sequential([iaa.Scale({\"height\": shape[0], \"width\": shape[1]})])\n",
        "    return seq.augment_images(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d5f083dfa8904a9bd7433e385ad2a0b8a236b22",
        "id": "Zw3sldJUyLGg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_prev_model(model_small=None):\n",
        "#     print(os.popen('du -sh '+colab_dir+'*').read())\n",
        "    last_best=os.popen('du -sh '+colab_dir+r'*|sed -r \"s/^[0-9\\.]+[MK]?\\s(.*)$/\\1/g;\"|tail -1').read().strip()\n",
        "    model_prev=None\n",
        "    try:\n",
        "        print('Attempting to load last best model from file - ',end='')\n",
        "        last_best_fn=last_best.split('/')[-1]\n",
        "        last_best_epoch=last_best_fn.split('.')[1].split('-')[0]\n",
        "        model_prev=load_model(last_best)\n",
        "        print('Sucess\\nLoaded '+last_best_fn, 'epoch :', last_best_epoch)\n",
        "    except Exception as e:\n",
        "        print('Failed!\\n',e)\n",
        "        try:\n",
        "            print('Attempting to load last saved model from file - ',end='')\n",
        "            model_prev = load_model(model_file)\n",
        "            print('Sucess\\nLoaded model from file',model_file)\n",
        "        except Exception as e:\n",
        "    #         print(str(e), 'at line ', sys.exc_info()[2].tb_lineno)\n",
        "            print('Failed!\\n',e)\n",
        "            try:\n",
        "                print('Attempting to load in memory, small model - ',end='')\n",
        "                if len(model_small.layers)>1:\n",
        "                    model_prev=model_small\n",
        "                print('Sucess')\n",
        "            except Exception as e:\n",
        "                print('Failed!\\n',e)\n",
        "    return model_prev\n",
        "  \n",
        "def copy_weights(model_to,model_from):\n",
        "    #model_to.set_weights(model_from.get_weights())\n",
        "    s,err=0,0\n",
        "    print('Trying to copy weights')\n",
        "    try:\n",
        "        if len(model_to.layers) >1 and len(model_from.layers) >1:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        print('Inavlid models',model_to,model_from)\n",
        "        return\n",
        "    for new_layer, layer in zip(model_to.layers[1:], model_from.layers[1:]):\n",
        "        s+=1\n",
        "        try:\n",
        "            new_layer.set_weights(layer.get_weights())\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    print('Done: errors:',err)\n",
        "      \n",
        "#new model with larger i/p layer\n",
        "def larger_model(src_model,shape=(32,32,3)):\n",
        "    new_input=Input(shape)\n",
        "    src_model.layers.pop(0)\n",
        "    new_output=src_model(new_input)\n",
        "    new_model=Model(new_input,new_output)\n",
        "    return new_model\n",
        "\n",
        "# Load CIFAR10 Data\n",
        "def load_data(resize=False,na=False,shape=(26,26),test_augment=False):\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    \n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    if resize:\n",
        "        x_train=resize_imgs(x_train,shape)\n",
        "        x_test=resize_imgs(x_test,shape)\n",
        "    \n",
        "    (x_train, y_train) = augmenter(x_train, y_train,end=1,na=na)\n",
        "    if test_augment:\n",
        "        (x_test, y_test) = augmenter(x_test, y_test,end=1,na=na)\n",
        "    return (x_train, y_train,x_test, y_test)\n",
        "#create a dnn model\n",
        "def create_model(input_shape,num_layers,input_conv_filters=12,input=None):\n",
        "    print('Creating model with input shape',input_shape)\n",
        "    if input is None:\n",
        "        input = Input(input_shape)\n",
        "    First_Conv2D = Conv2D(input_conv_filters, (3,3), use_bias=False ,padding='same')(input)\n",
        "    hidden_dense_blocks = dense_units_chain(n_dense_blocks,First_Conv2D,num_filter,dropout_rate,num_layers)\n",
        "    Last_Block = add_denseblock(hidden_dense_blocks, num_filter, dropout_rate)\n",
        "    output = output_layer(Last_Block)\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5QrXF2BznZs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Dense Block\n",
        "def add_denseblock(input,num_layers, growth_rate = 12, dropout_rate = 0.2,bn_layers=48,middle_layers=24):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(num_layers):\n",
        "        ######################################################################################################################################\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)        \n",
        "        Conv2D_1_1_bottleneck = Conv2D(bn_layers, (1,1), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #bottleneck  <===\n",
        "        ###################################################################################################################################### |\n",
        "        BatchNorm = BatchNormalization()(Conv2D_1_1_bottleneck) #extra layer                                                                 # |\n",
        "        relu = Activation('relu')(BatchNorm) #extra layer                                                                                    # |\n",
        "        Conv2D_1_1 = Conv2D(middle_layers, (1,1), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu) #extra layer          # |\n",
        "        ###################################################################################################################################### |\n",
        "        BatchNorm = BatchNormalization()(Conv2D_1_1) #bottleneck   <================================================================\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(growth_rate, (3,3), use_bias=False ,padding='same',kernel_initializer='he_normal')(relu)\n",
        "        ######################################################################################################################################|\n",
        "        \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg\n",
        "\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    GlobalAveragePooling = GlobalAveragePooling2D(data_format='channels_last')(relu)\n",
        "#     flat = Flatten()(GlobalAveragePooling)\n",
        "    output = Dense(num_classes, activation='softmax')(GlobalAveragePooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWb3CVJPz6_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbc=TensorBoardColabCallback(TensorBoardColab())\n",
        "num_filter = 0 # add it up as you go\n",
        "compression = 0.5\n",
        "dropout_rate = 0.5\n",
        "num_classes = 10\n",
        "\n",
        "layer_models=[[48,24,12],[48,20,7],[48,16,5],[40,20,10]]\n",
        "layer_models_index=-1\n",
        "\n",
        "bn_layers,middle_layers,growth_rate=layer_models[layer_models_index]\n",
        "\n",
        "\n",
        "\n",
        "num_layers=10#16#15\n",
        "batch_size=100\n",
        "initial_layers=12\n",
        "hist=[]\n",
        "# input = Input(shape=(img_height, img_width, channel,))\n",
        "input = Input(shape=(32, 32, 3,))\n",
        "First_Conv2D = Conv2D(initial_layers, (3,3), use_bias=False ,padding='same')(input)\n",
        "num_filter=initial_layers\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D,num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "num_filter+=growth_rate*num_layers\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "num_filter=num_filter//2\n",
        "Second_Block = add_denseblock(First_Transition, num_layers,growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "num_filter+=growth_rate*num_layers\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "num_filter=num_filter//2\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition,num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "num_filter+=growth_rate*num_layers\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition, num_layers, growth_rate, dropout_rate,bn_layers,middle_layers)\n",
        "# Last_Block=Third_Block\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnCBJrCs11vl",
        "colab_type": "code",
        "outputId": "f1ed6bf5-9d1a-4b6c-cf0c-7c65a093b77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16490
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 32, 32, 12)   324         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 32, 32, 12)   48          conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 32, 32, 12)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 32, 32, 40)   480         activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 32, 32, 40)   160         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 32, 32, 40)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 32, 32, 20)   800         activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 32, 32, 20)   80          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 32, 32, 20)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 32, 32, 10)   1800        activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 32, 32, 10)   0           conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 32, 32, 22)   0           conv2d_197[0][0]                 \n",
            "                                                                 dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 32, 32, 22)   88          concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 32, 32, 22)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 32, 32, 40)   880         activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 32, 32, 40)   160         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 32, 32, 40)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 32, 32, 20)   800         activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 32, 32, 20)   80          conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 32, 32, 20)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 32, 32, 10)   1800        activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 32, 32, 10)   0           conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 32, 32, 32)   0           concatenate_65[0][0]             \n",
            "                                                                 dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 32, 32, 32)   128         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 32, 32, 32)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 32, 32, 40)   1280        activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 32, 32, 40)   160         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 32, 32, 40)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 32, 32, 20)   800         activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 32, 32, 20)   80          conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 32, 32, 20)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 32, 32, 10)   1800        activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 32, 32, 10)   0           conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 32, 32, 42)   0           concatenate_66[0][0]             \n",
            "                                                                 dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 32, 32, 42)   168         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 32, 32, 42)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 32, 32, 40)   1680        activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 32, 32, 40)   160         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 32, 32, 40)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 32, 32, 20)   800         activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 32, 32, 20)   80          conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 32, 32, 20)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 32, 32, 10)   1800        activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 32, 32, 10)   0           conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 32, 32, 52)   0           concatenate_67[0][0]             \n",
            "                                                                 dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 32, 32, 52)   208         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 32, 32, 52)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 32, 32, 40)   2080        activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 32, 32, 40)   160         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 32, 32, 40)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 32, 32, 20)   800         activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 32, 32, 20)   80          conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 32, 32, 20)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 32, 32, 10)   1800        activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 32, 32, 10)   0           conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 32, 32, 62)   0           concatenate_68[0][0]             \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 32, 32, 62)   248         concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 32, 32, 62)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 32, 32, 40)   2480        activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 32, 32, 40)   160         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 32, 32, 40)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 32, 32, 20)   800         activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 32, 32, 20)   80          conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 32, 32, 20)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 32, 32, 10)   1800        activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 32, 32, 10)   0           conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 32, 32, 72)   0           concatenate_69[0][0]             \n",
            "                                                                 dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 32, 32, 72)   288         concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 32, 32, 72)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 32, 32, 40)   2880        activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 32, 32, 40)   160         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 32, 32, 40)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 32, 32, 20)   800         activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 32, 32, 20)   80          conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 32, 32, 20)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 32, 32, 10)   1800        activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 32, 32, 10)   0           conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 32, 32, 82)   0           concatenate_70[0][0]             \n",
            "                                                                 dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 32, 32, 82)   328         concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 32, 32, 82)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 32, 32, 40)   3280        activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 32, 32, 40)   160         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 32, 32, 40)   0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 32, 32, 20)   800         activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 32, 32, 20)   80          conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 32, 32, 20)   0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 32, 32, 10)   1800        activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 32, 32, 10)   0           conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 32, 32, 92)   0           concatenate_71[0][0]             \n",
            "                                                                 dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 32, 32, 92)   368         concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 32, 32, 92)   0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 32, 32, 40)   3680        activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 32, 32, 40)   160         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 32, 32, 40)   0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 32, 32, 20)   800         activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 32, 32, 20)   80          conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 32, 32, 20)   0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 32, 32, 10)   1800        activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 32, 32, 10)   0           conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 32, 32, 102)  0           concatenate_72[0][0]             \n",
            "                                                                 dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 32, 32, 102)  408         concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 32, 32, 102)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 32, 32, 40)   4080        activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 32, 32, 40)   160         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 32, 32, 40)   0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 32, 32, 20)   800         activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 32, 32, 20)   80          conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 32, 32, 20)   0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 32, 32, 10)   1800        activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 32, 32, 10)   0           conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 32, 32, 112)  0           concatenate_73[0][0]             \n",
            "                                                                 dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 32, 32, 112)  448         concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 32, 32, 112)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 32, 32, 56)   6272        activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 32, 32, 56)   0           conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 16, 16, 56)   0           dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 16, 16, 56)   224         average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 16, 16, 56)   0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 16, 16, 40)   2240        activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 16, 16, 40)   160         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 16, 16, 40)   0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 16, 16, 20)   800         activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 16, 16, 20)   80          conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 16, 16, 20)   0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 16, 16, 10)   1800        activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 16, 16, 10)   0           conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 16, 16, 66)   0           average_pooling2d_4[0][0]        \n",
            "                                                                 dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 16, 16, 66)   264         concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 16, 16, 66)   0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 16, 16, 40)   2640        activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 16, 16, 40)   160         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 16, 16, 40)   0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 16, 16, 20)   800         activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 16, 16, 20)   80          conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 16, 16, 20)   0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 16, 16, 10)   1800        activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 16, 16, 10)   0           conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 16, 16, 76)   0           concatenate_75[0][0]             \n",
            "                                                                 dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 16, 16, 76)   304         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 16, 16, 76)   0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 16, 16, 40)   3040        activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 16, 16, 40)   160         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 16, 16, 40)   0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 16, 16, 20)   800         activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 16, 16, 20)   80          conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 16, 16, 20)   0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 16, 16, 10)   1800        activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 16, 16, 10)   0           conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 16, 16, 86)   0           concatenate_76[0][0]             \n",
            "                                                                 dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 16, 16, 86)   344         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 16, 16, 86)   0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 16, 16, 40)   3440        activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 16, 16, 40)   160         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 16, 16, 40)   0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 16, 16, 20)   800         activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 16, 16, 20)   80          conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 16, 16, 20)   0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 16, 16, 10)   1800        activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 16, 16, 10)   0           conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 16, 16, 96)   0           concatenate_77[0][0]             \n",
            "                                                                 dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 16, 16, 96)   384         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 16, 16, 96)   0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 16, 16, 40)   3840        activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 16, 16, 40)   160         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 16, 16, 40)   0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 16, 16, 20)   800         activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 16, 16, 20)   80          conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 16, 16, 20)   0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 16, 16, 10)   1800        activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 16, 16, 10)   0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 16, 16, 106)  0           concatenate_78[0][0]             \n",
            "                                                                 dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 16, 16, 106)  424         concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 16, 16, 106)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 16, 16, 40)   4240        activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 16, 16, 40)   160         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 16, 16, 40)   0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 16, 16, 20)   800         activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 16, 16, 20)   80          conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 16, 16, 20)   0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 16, 16, 10)   1800        activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 16, 16, 10)   0           conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 16, 16, 116)  0           concatenate_79[0][0]             \n",
            "                                                                 dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 16, 16, 116)  464         concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 16, 16, 116)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 16, 16, 40)   4640        activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 16, 16, 40)   160         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 16, 16, 40)   0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 16, 16, 20)   800         activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 16, 16, 20)   80          conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 16, 16, 20)   0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 16, 16, 10)   1800        activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 16, 16, 10)   0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 16, 16, 126)  0           concatenate_80[0][0]             \n",
            "                                                                 dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 16, 16, 126)  504         concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 16, 16, 126)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 16, 16, 40)   5040        activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 16, 16, 40)   160         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 16, 16, 40)   0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 16, 16, 20)   800         activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 16, 16, 20)   80          conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 16, 16, 20)   0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 16, 16, 10)   1800        activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 16, 16, 10)   0           conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 16, 16, 136)  0           concatenate_81[0][0]             \n",
            "                                                                 dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 16, 16, 136)  544         concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 16, 16, 136)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 16, 16, 40)   5440        activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 16, 16, 40)   160         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 16, 16, 40)   0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 16, 16, 20)   800         activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 16, 16, 20)   80          conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 16, 16, 20)   0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 16, 16, 10)   1800        activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 16, 16, 10)   0           conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 16, 16, 146)  0           concatenate_82[0][0]             \n",
            "                                                                 dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 16, 16, 146)  584         concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 16, 16, 146)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 16, 16, 40)   5840        activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 16, 16, 40)   160         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 16, 16, 40)   0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 16, 16, 20)   800         activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 16, 16, 20)   80          conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 16, 16, 20)   0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 16, 16, 10)   1800        activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 16, 16, 10)   0           conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 16, 16, 156)  0           concatenate_83[0][0]             \n",
            "                                                                 dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 16, 16, 156)  624         concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 16, 16, 156)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 16, 16, 78)   12168       activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 16, 16, 78)   0           conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 8, 8, 78)     0           dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 8, 8, 78)     312         average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 8, 8, 78)     0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 8, 8, 40)     3120        activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 8, 8, 40)     160         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 8, 8, 40)     0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 8, 8, 20)     800         activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 8, 8, 20)     80          conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 8, 8, 20)     0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 8, 8, 10)     1800        activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 8, 8, 10)     0           conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 8, 8, 88)     0           average_pooling2d_5[0][0]        \n",
            "                                                                 dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 8, 8, 88)     352         concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 8, 8, 88)     0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 8, 8, 40)     3520        activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 8, 8, 40)     160         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 8, 8, 40)     0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 8, 8, 20)     800         activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 8, 8, 20)     80          conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 8, 8, 20)     0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 8, 8, 10)     1800        activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 8, 8, 10)     0           conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_86 (Concatenate)    (None, 8, 8, 98)     0           concatenate_85[0][0]             \n",
            "                                                                 dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 8, 8, 98)     392         concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 8, 8, 98)     0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 8, 8, 40)     3920        activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 8, 8, 40)     160         conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 8, 8, 40)     0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 20)     800         activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 20)     80          conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 8, 8, 20)     0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 10)     1800        activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 8, 8, 10)     0           conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_87 (Concatenate)    (None, 8, 8, 108)    0           concatenate_86[0][0]             \n",
            "                                                                 dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 108)    432         concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 8, 8, 108)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 40)     4320        activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 40)     160         conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 8, 8, 40)     0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 8, 8, 20)     800         activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 8, 8, 20)     80          conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 8, 8, 20)     0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 8, 8, 10)     1800        activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 8, 8, 10)     0           conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 8, 8, 118)    0           concatenate_87[0][0]             \n",
            "                                                                 dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 8, 8, 118)    472         concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 8, 8, 118)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 40)     4720        activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 8, 8, 40)     160         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 8, 8, 40)     0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 20)     800         activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 8, 8, 20)     80          conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 8, 8, 20)     0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 10)     1800        activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 8, 8, 10)     0           conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 8, 8, 128)    0           concatenate_88[0][0]             \n",
            "                                                                 dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 8, 8, 128)    512         concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 8, 8, 128)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 40)     5120        activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 40)     160         conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 40)     0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 20)     800         activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 8, 8, 20)     80          conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 8, 8, 20)     0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 10)     1800        activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 8, 8, 10)     0           conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 8, 8, 138)    0           concatenate_89[0][0]             \n",
            "                                                                 dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 8, 8, 138)    552         concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 8, 8, 138)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 40)     5520        activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 40)     160         conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 40)     0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 20)     800         activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 20)     80          conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 20)     0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 10)     1800        activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 8, 8, 10)     0           conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 8, 8, 148)    0           concatenate_90[0][0]             \n",
            "                                                                 dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 8, 8, 148)    592         concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 8, 8, 148)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 40)     5920        activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 8, 8, 40)     160         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 8, 8, 40)     0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 8, 8, 20)     800         activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 8, 8, 20)     80          conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 8, 8, 20)     0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 8, 8, 10)     1800        activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 8, 8, 10)     0           conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 8, 8, 158)    0           concatenate_91[0][0]             \n",
            "                                                                 dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 8, 8, 158)    632         concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 8, 8, 158)    0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 8, 8, 40)     6320        activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 8, 8, 40)     160         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 8, 8, 40)     0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 8, 8, 20)     800         activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 8, 8, 20)     80          conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 8, 8, 20)     0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 8, 8, 10)     1800        activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 8, 8, 10)     0           conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 8, 8, 168)    0           concatenate_92[0][0]             \n",
            "                                                                 dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 8, 8, 168)    672         concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 8, 8, 168)    0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 8, 8, 40)     6720        activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 8, 8, 40)     160         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 8, 8, 40)     0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 8, 8, 20)     800         activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 8, 8, 20)     80          conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 8, 8, 20)     0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 8, 8, 10)     1800        activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 8, 8, 10)     0           conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 8, 8, 178)    0           concatenate_93[0][0]             \n",
            "                                                                 dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 8, 8, 178)    712         concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 8, 8, 178)    0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 8, 8, 89)     15842       activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 8, 8, 89)     0           conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 89)     0           dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 4, 4, 89)     356         average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 4, 4, 89)     0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 4, 4, 40)     3560        activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 4, 4, 40)     160         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 4, 4, 40)     0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 4, 4, 20)     800         activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 4, 4, 20)     80          conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 4, 4, 20)     0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 4, 4, 10)     1800        activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 4, 4, 10)     0           conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 4, 4, 99)     0           average_pooling2d_6[0][0]        \n",
            "                                                                 dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 4, 4, 99)     396         concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 4, 4, 99)     0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 4, 4, 40)     3960        activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 4, 4, 40)     160         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 4, 4, 40)     0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 4, 4, 20)     800         activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 4, 4, 20)     80          conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 4, 4, 20)     0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 4, 4, 10)     1800        activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 4, 4, 10)     0           conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 4, 4, 109)    0           concatenate_95[0][0]             \n",
            "                                                                 dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 4, 4, 109)    436         concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 4, 4, 109)    0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 4, 4, 40)     4360        activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 4, 4, 40)     160         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 4, 4, 40)     0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 4, 4, 20)     800         activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 4, 4, 20)     80          conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 4, 4, 20)     0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 4, 4, 10)     1800        activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 4, 4, 10)     0           conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 4, 4, 119)    0           concatenate_96[0][0]             \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 4, 4, 119)    476         concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 4, 4, 119)    0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 4, 4, 40)     4760        activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 4, 4, 40)     160         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 4, 4, 40)     0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 4, 4, 20)     800         activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 4, 4, 20)     80          conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 4, 4, 20)     0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 4, 4, 10)     1800        activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 4, 4, 10)     0           conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 4, 4, 129)    0           concatenate_97[0][0]             \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 4, 4, 129)    516         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 4, 4, 129)    0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 4, 4, 40)     5160        activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 4, 4, 40)     160         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 4, 4, 40)     0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 4, 4, 20)     800         activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 4, 4, 20)     80          conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 4, 4, 20)     0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 4, 4, 10)     1800        activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 4, 4, 10)     0           conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 4, 4, 139)    0           concatenate_98[0][0]             \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 4, 4, 139)    556         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 4, 4, 139)    0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 4, 4, 40)     5560        activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 4, 4, 40)     160         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 4, 4, 40)     0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 4, 4, 20)     800         activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 4, 4, 20)     80          conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 4, 4, 20)     0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 4, 4, 10)     1800        activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 4, 4, 10)     0           conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 4, 4, 149)    0           concatenate_99[0][0]             \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 4, 4, 149)    596         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 4, 4, 149)    0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 4, 4, 40)     5960        activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 4, 4, 40)     160         conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 4, 4, 40)     0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 4, 4, 20)     800         activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 4, 4, 20)     80          conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 4, 4, 20)     0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 4, 4, 10)     1800        activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 4, 4, 10)     0           conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 4, 4, 159)    0           concatenate_100[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 4, 4, 159)    636         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 4, 4, 159)    0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 4, 4, 40)     6360        activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 4, 4, 40)     160         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 4, 4, 40)     0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 4, 4, 20)     800         activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 4, 4, 20)     80          conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 4, 4, 20)     0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 4, 4, 10)     1800        activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 4, 4, 10)     0           conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 4, 4, 169)    0           concatenate_101[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 4, 4, 169)    676         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 4, 4, 169)    0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 4, 4, 40)     6760        activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 4, 4, 40)     160         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 4, 4, 40)     0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 4, 4, 20)     800         activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 4, 4, 20)     80          conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 4, 4, 20)     0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 4, 4, 10)     1800        activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 4, 4, 10)     0           conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 4, 4, 179)    0           concatenate_102[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 4, 4, 179)    716         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 4, 4, 179)    0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 4, 4, 40)     7160        activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 4, 4, 40)     160         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 4, 4, 40)     0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 4, 4, 20)     800         activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 4, 4, 20)     80          conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 4, 4, 20)     0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 4, 4, 10)     1800        activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 4, 4, 10)     0           conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 4, 4, 189)    0           concatenate_103[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 4, 4, 189)    756         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 4, 4, 189)    0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 189)          0           activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1900        global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 335,246\n",
            "Trainable params: 320,876\n",
            "Non-trainable params: 14,370\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "991f8e371577a1f2e8197827dab5aac2406ef1b1",
        "id": "kpe9EljYyLGq",
        "colab_type": "code",
        "outputId": "d3b0938d-d4c6-4b5d-aaa1-ca509af2f7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('====================HYPER PARAMETERS====================')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================HYPER PARAMETERS====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "7c17f4244c917e97e7cc1557ae60bce8dba7e47e",
        "id": "JVTAyE2OyLIW",
        "colab_type": "code",
        "outputId": "7ac586be-798f-4c08-8f47-0a072a79f33a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "x_train, y_train, x_test, y_test = load_data(resize=False,na=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 36s 0us/step\n",
            "Before augmentation: (50000, 32, 32, 3) (50000, 10)\n",
            "After augmentation: (50000, 32, 32, 3) (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A89juSamtr--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callbacks\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.09, max_lr=0.3,step_size=4*(len(y_train)/batch_size))\n",
        "\n",
        "callbacks = [ model_checkpointer,tbc]\n",
        "hist=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "53b7ed0b0e8acefefda51802f0bd74f0cace4c72",
        "id": "hx_zlXvhyLIy",
        "colab_type": "code",
        "outputId": "96b2edef-c5cc-49c0-a446-8aa313d2e8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,epochs=20, callbacks=callbacks, validation_data=(x_test,y_test))\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GDR1Xkqg8x-t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h=hist[-1].history\n",
        "lr = h['lr']\n",
        "acc = h['acc']\n",
        "val_acc=h['val_acc']\n",
        "\n",
        "f, ax_arr = plt.subplots(1, 2)\n",
        "ax_arr[0].plot(lr,acc,label='acc')\n",
        "ax_arr[0].set_title('Training accuracy')\n",
        "ax_arr[1].plot(lr,val_acc,label='val_acc')\n",
        "ax_arr[1].set_title('Validation accuracy')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "line1,=ax.plot(acc,label='train_acc')\n",
        "line2,=ax.plot(val_acc,label='val_acc')\n",
        "\n",
        "ax.legend(handles=[line1, line2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ojsf8gZxPf7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model=load_model(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHe0wB1T75fo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size=128\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.01, max_lr=0.1,step_size=8*(len(y_train)/batch_size))\n",
        "\n",
        "callbacks = [model_checkpointer,clr,tbc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wZvE3aA8Dju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=10,epochs=40+20, callbacks=callbacks, validation_data=(x_test, y_test))#validation_split=0.1)#\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PK76TUbIuzIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h=hist[-1].history\n",
        "lr = h['lr']\n",
        "acc = h['acc']\n",
        "val_acc=h['val_acc']\n",
        "\n",
        "f, ax_arr = plt.subplots(1, 2)\n",
        "ax_arr[0].plot(lr,acc,label='acc')\n",
        "ax_arr[0].set_title('Training accuracy')\n",
        "ax_arr[1].plot(lr,val_acc,label='val_acc')\n",
        "ax_arr[1].set_title('Validation accuracy')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "line1,=ax.plot(acc,label='train_acc')\n",
        "line2,=ax.plot(val_acc,label='val_acc')\n",
        "\n",
        "ax.legend(handles=[line1, line2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7CtN1Q2rCLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size=128\n",
        "model_checkpointer=ModelCheckpoint(weights_dir+'large_weights.{epoch:02d}-{val_acc:.2f}.h5', monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=2)\n",
        "clr = CyclicLR(base_lr=0.001, max_lr=0.01,step_size=8*(len(y_train)/batch_size))\n",
        "\n",
        "callbacks = [ model_checkpointer,clr,tbc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "163k0yMa-BJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# m=load_model('/content/gdrive/My Drive/Colab Notebooks/weights/large_weights.20-0.89.h5')\n",
        "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=SGD(lr=0.1, decay=1e-4, momentum=0.9, nesterov=True))\n",
        "# model.set_weights(m.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1TuicAOEEic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# del m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdKIit76rCPN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h=model.fit(x_train, y_train, batch_size=batch_size, verbose=1,initial_epoch=40+20,epochs=40+20+20, callbacks=callbacks, validation_split=0.1)\n",
        "hist.append(h)\n",
        "model.save(model_file)\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ws-gvUyn_GSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h=hist[-1].history\n",
        "lr = h['lr']\n",
        "acc = h['acc']\n",
        "val_acc=h['val_acc']\n",
        "\n",
        "f, ax_arr = plt.subplots(1, 2)\n",
        "ax_arr[0].plot(lr,acc,label='acc')\n",
        "ax_arr[0].set_title('Training accuracy')\n",
        "ax_arr[1].plot(lr,val_acc,label='val_acc')\n",
        "ax_arr[1].set_title('Validation accuracy')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "line1,=ax.plot(acc,label='train_acc')\n",
        "line2,=ax.plot(val_acc,label='val_acc')\n",
        "\n",
        "ax.legend(handles=[line1, line2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7be8a1352f65787da27dc9eeb8b9073890561062",
        "id": "YmAAYyWYyLJ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6151d97fb488aed1553bb9ae29fcb9e3e0bf1f08",
        "id": "kEa47QYDyLJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('====================END OF LARGER MODEL====================')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4BQiFHzvyLKb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}